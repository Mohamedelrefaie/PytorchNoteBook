{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:40:58.010837Z",
     "start_time": "2021-01-31T09:40:58.003972Z"
    }
   },
   "source": [
    "# fastai datacore\n",
    "> borrow code from https://docs.fast.ai/data.core.html add some tips\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- sticky_rank: 2\n",
    "- author: Bowen\n",
    "- categories: [pytorch, fastai]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:22.205144Z",
     "start_time": "2021-01-31T02:50:21.804616Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:22.210324Z",
     "start_time": "2021-01-31T02:50:22.207573Z"
    }
   },
   "outputs": [],
   "source": [
    "#default_exp data.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.766468Z",
     "start_time": "2021-01-31T02:50:22.212630Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.load import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.902531Z",
     "start_time": "2021-01-31T02:50:23.768169Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.913476Z",
     "start_time": "2021-01-31T02:50:23.904130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7) [Path('/home/ubuntu/.fastai/data/isprs/5_Labels_for_participants.zip'),Path('/home/ubuntu/.fastai/data/isprs/4_Ortho_RGBIR.zip'),Path('/home/ubuntu/.fastai/data/isprs/haze'),Path('/home/ubuntu/.fastai/data/isprs/2_Ortho_RGB.zip'),Path('/home/ubuntu/.fastai/data/isprs/Vaihingen'),Path('/home/ubuntu/.fastai/data/isprs/Potsdam'),Path('/home/ubuntu/.fastai/data/isprs/bak')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/home/ubuntu/.fastai/data/isprs/Potsdam/2_Ortho_RGB/train_pick/top_potsdam_7_9_RGB.tif'),Path('/home/ubuntu/.fastai/data/isprs/Potsdam/2_Ortho_RGB/train_pick/top_potsdam_5_10_RGB.tif'),Path('/home/ubuntu/.fastai/data/isprs/Potsdam/2_Ortho_RGB/train_pick/top_potsdam_5_11_RGB.tif')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/home/ubuntu/.fastai/data/isprs/Potsdam/5_Labels_for_participants/top_potsdam_7_7_label.tif'),Path('/home/ubuntu/.fastai/data/isprs/Potsdam/5_Labels_for_participants/top_potsdam_2_10_label.tif'),Path('/home/ubuntu/.fastai/data/isprs/Potsdam/5_Labels_for_participants/top_potsdam_6_8_label.tif')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('/home/ubuntu/.fastai/data/isprs/')\n",
    "data_path.ls()\n",
    "# path_img = data_path/'2_Ortho_RGB'\n",
    "# path_lbl = data_path/'5_Labels_for_participants'\n",
    "path_img = data_path / 'Potsdam/2_Ortho_RGB/train_pick'\n",
    "path_lbl = data_path / 'Potsdam/5_Labels_for_participants'\n",
    "fnames = get_image_files(path_img)\n",
    "fnames[:3]\n",
    "lbl_names = get_image_files(path_lbl)\n",
    "lbl_names[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data core\n",
    "\n",
    "> Core functionality for gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for applying a list of transforms to a set of items (`TfmdLists`, `Datasets`) or a `DataLoader` (`TfmdDl`) as well as the base class used to gather the data for model training: `DataLoaders`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDL -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.919064Z",
     "start_time": "2021-01-31T02:50:23.914587Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@typedispatch\n",
    "def show_batch(x, y, samples, ctxs=None, max_n=9, **kwargs):\n",
    "    if ctxs is None: ctxs = Inf.nones\n",
    "    if hasattr(samples[0], 'show'):\n",
    "        ctxs = [s.show(ctx=c, **kwargs) for s,c,_ in zip(samples,ctxs,range(max_n))]\n",
    "    else:\n",
    "        for i in range_of(samples[0]):\n",
    "            ctxs = [b.show(ctx=c, **kwargs) for b,c,_ in zip(samples.itemgot(i),ctxs,range(max_n))]\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_batch` is a type-dispatched function that is responsible for showing decoded `samples`. `x` and `y` are the input and the target in the batch to be shown, and are passed along to dispatch on their types. There is a different implementation of `show_batch` if `x` is a `TensorImage` or a `TensorText` for instance (see vision.core or text.data for more details). `ctxs` can be passed but the function is responsible to create them if necessary. `kwargs` depend on the specific implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.925741Z",
     "start_time": "2021-01-31T02:50:23.920362Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@typedispatch\n",
    "def show_results(x, y, samples, outs, ctxs=None, max_n=9, **kwargs):\n",
    "    if ctxs is None: ctxs = Inf.nones\n",
    "    for i in range(len(samples[0])):\n",
    "        ctxs = [b.show(ctx=c, **kwargs) for b,c,_ in zip(samples.itemgot(i),ctxs,range(max_n))]\n",
    "    for i in range(len(outs[0])):\n",
    "        ctxs = [b.show(ctx=c, **kwargs) for b,c,_ in zip(outs.itemgot(i),ctxs,range(max_n))]\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_results` is a type-dispatched function that is responsible for showing decoded `samples` and their corresponding `outs`. Like in `show_batch`, `x` and `y` are the input and the target in the batch to be shown, and are passed along to dispatch on their types. `ctxs` can be passed but the function is responsible to create them if necessary. `kwargs` depend on the specific implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.932130Z",
     "start_time": "2021-01-31T02:50:23.927569Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "_all_ = [\"show_batch\", \"show_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.941377Z",
     "start_time": "2021-01-31T02:50:23.933413Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "_batch_tfms = ('after_item','before_batch','after_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.963399Z",
     "start_time": "2021-01-31T02:50:23.942614Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@delegates()\n",
    "class TfmdDL(DataLoader):\n",
    "    \"Transformed `DataLoader`\"\n",
    "    def __init__(self, dataset, bs=64, shuffle=False, num_workers=None, verbose=False, do_setup=True, **kwargs):\n",
    "        if num_workers is None: num_workers = min(16, defaults.cpus)\n",
    "        for nm in _batch_tfms: kwargs[nm] = Pipeline(kwargs.get(nm,None))\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, num_workers=num_workers, **kwargs)\n",
    "        if do_setup:\n",
    "            for nm in _batch_tfms:\n",
    "                pv(f\"Setting up {nm}: {kwargs[nm]}\", verbose)\n",
    "                kwargs[nm].setup(self)\n",
    "\n",
    "    def _one_pass(self):\n",
    "        b = self.do_batch([self.do_item(0)])\n",
    "        if self.device is not None: b = to_device(b, self.device)\n",
    "        its = self.after_batch(b)\n",
    "        self._n_inp = 1 if not isinstance(its, (list,tuple)) or len(its)==1 else len(its)-1\n",
    "        self._types = explode_types(its)\n",
    "\n",
    "    def _retain_dl(self,b):\n",
    "        if not getattr(self, '_types', None): self._one_pass()\n",
    "        return retain_types(b, typs=self._types)\n",
    "\n",
    "    @delegates(DataLoader.new)\n",
    "    def new(self, dataset=None, cls=None, **kwargs):\n",
    "        res = super().new(dataset, cls, do_setup=False, **kwargs)\n",
    "        if not hasattr(self, '_n_inp') or not hasattr(self, '_types'):\n",
    "            try:\n",
    "                self._one_pass()\n",
    "                res._n_inp,res._types = self._n_inp,self._types\n",
    "            except: print(\"Could not do one pass in your dataloader, there is something wrong in it\")\n",
    "        else: res._n_inp,res._types = self._n_inp,self._types\n",
    "        return res\n",
    "\n",
    "    def before_iter(self):\n",
    "        super().before_iter()\n",
    "        split_idx = getattr(self.dataset, 'split_idx', None)\n",
    "        for nm in _batch_tfms:\n",
    "            f = getattr(self,nm)\n",
    "            if isinstance(f,Pipeline): f.split_idx=split_idx\n",
    "\n",
    "    def decode(self, b): return to_cpu(self.after_batch.decode(self._retain_dl(b)))\n",
    "    def decode_batch(self, b, max_n=9, full=True): return self._decode_batch(self.decode(b), max_n, full)\n",
    "\n",
    "    def _decode_batch(self, b, max_n=9, full=True):\n",
    "        f = self.after_item.decode\n",
    "        f1 = self.before_batch.decode\n",
    "        f = compose(f1, f, partial(getattr(self.dataset,'decode',noop), full = full))\n",
    "        return L(batch_to_samples(b, max_n=max_n)).map(f)\n",
    "\n",
    "    def _pre_show_batch(self, b, max_n=9):\n",
    "        \"Decode `b` to be ready for `show_batch`\"\n",
    "        b = self.decode(b)\n",
    "        if hasattr(b, 'show'): return b,None,None\n",
    "        its = self._decode_batch(b, max_n, full=False)\n",
    "        if not is_listy(b): b,its = [b],L((o,) for o in its)\n",
    "        return detuplify(b[:self.n_inp]),detuplify(b[self.n_inp:]),its\n",
    "\n",
    "    def show_batch(self, b=None, max_n=9, ctxs=None, show=True, unique=False, **kwargs):\n",
    "        if unique:\n",
    "            old_get_idxs = self.get_idxs\n",
    "            self.get_idxs = lambda: Inf.zeros\n",
    "        if b is None: b = self.one_batch()\n",
    "        if not show: return self._pre_show_batch(b, max_n=max_n)\n",
    "        show_batch(*self._pre_show_batch(b, max_n=max_n), ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "        if unique: self.get_idxs = old_get_idxs\n",
    "\n",
    "    def show_results(self, b, out, max_n=9, ctxs=None, show=True, **kwargs):\n",
    "        x,y,its = self.show_batch(b, max_n=max_n, show=False)\n",
    "        b_out = type(b)(b[:self.n_inp] + (tuple(out) if is_listy(out) else (out,)))\n",
    "        x1,y1,outs = self.show_batch(b_out, max_n=max_n, show=False)\n",
    "        res = (x,x1,None,None) if its is None else (x, y, its, outs.itemgot(slice(self.n_inp,None)))\n",
    "        if not show: return res\n",
    "        show_results(*res, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def n_inp(self):\n",
    "        if hasattr(self.dataset, 'n_inp'): return self.dataset.n_inp\n",
    "        if not hasattr(self, '_n_inp'): self._one_pass()\n",
    "        return self._n_inp\n",
    "\n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        for tfm in self.after_batch.fs:\n",
    "            for a in L(getattr(tfm, 'parameters', None)): setattr(tfm, a, getattr(tfm, a).to(device))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TfmdDL` is a `DataLoader` that creates `Pipeline` from a list of `Transform`s for the callbacks `after_item`, `before_batch` and `after_batch`. As a result, it can decode or show a processed `batch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T03:40:06.809332Z",
     "start_time": "2021-01-31T03:40:06.803788Z"
    }
   },
   "source": [
    "\n",
    "(TfmdDL,\n",
    "         decode=\"Decode `b` using `tfms`\",\n",
    "         decode_batch=\"Decode `b` entirely\",\n",
    "         new=\"Create a new version of self with a few changed attributes\",\n",
    "         show_batch=\"Show `b` (defaults to `one_batch`), a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\",\n",
    "         show_results=\"Show each item of `b` and `out`\",\n",
    "         before_iter=\"override\",\n",
    "         to=\"Put self and its transforms state on `device`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.979695Z",
     "start_time": "2021-01-31T02:50:23.973868Z"
    }
   },
   "outputs": [],
   "source": [
    "class _Category(int, ShowTitle): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:23.988096Z",
     "start_time": "2021-01-31T02:50:23.981174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2118,  0.8821,  0.2013, -0.3173,  0.5078]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = torch.randn(1,5)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:24.039193Z",
     "start_time": "2021-01-31T02:50:23.989875Z"
    }
   },
   "outputs": [],
   "source": [
    "TensorImage??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T04:36:34.769618Z",
     "start_time": "2021-01-31T04:36:34.749637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([[-1],\n",
       "         [-1],\n",
       "         [-1],\n",
       "         [-1]]),)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test retain type\n",
    "class NegTfm(Transform):\n",
    "    def encodes(self, x): return torch.neg(x)\n",
    "    def decodes(self, x): return torch.neg(x)\n",
    "    \n",
    "tdl = TfmdDL([(TensorImage([1]),)] * 16, after_batch=NegTfm(), bs=4, num_workers=4)\n",
    "b = tdl.one_batch()\n",
    "b\n",
    "test_eq(type(b[0]), TensorImage)\n",
    "b = (tensor([1.,1.,1.,1.]),)\n",
    "test_eq(type(tdl.decode_batch(b)[0][0]), TensorImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:24.057292Z",
     "start_time": "2021-01-31T02:50:24.053071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2118, -0.8821, -0.2013,  0.3173, -0.5078]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = NegTfm()(aa)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:50:24.063410Z",
     "start_time": "2021-01-31T02:50:24.058532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2118,  0.8821,  0.2013, -0.3173,  0.5078]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NegTfm().decodes(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:53:07.557876Z",
     "start_time": "2021-01-31T02:53:07.550478Z"
    }
   },
   "outputs": [],
   "source": [
    "class A(Transform): \n",
    "    def encodes(self, x): return x \n",
    "    def decodes(self, x): return TitledInt(x) \n",
    "\n",
    "@Transform\n",
    "def f(x)->None: return fastuple((x,x))\n",
    "\n",
    "start = torch.arange(50)\n",
    "test_eq_type(f(2), fastuple((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:53:07.920240Z",
     "start_time": "2021-01-31T02:53:07.916264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T02:54:29.447139Z",
     "start_time": "2021-01-31T02:54:29.429743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#4) [(tensor(0), (tensor(0), tensor(0))),(tensor(1), (tensor(1), tensor(1))),(tensor(2), (tensor(2), tensor(2))),(tensor(3), (tensor(3), tensor(3)))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = A()\n",
    "tdl = TfmdDL(start, after_item=lambda x: (a(x), f(x)), bs=4)\n",
    "x,y = tdl.one_batch()\n",
    "x\n",
    "y\n",
    "test_eq(type(y), fastuple)\n",
    "\n",
    "s = tdl.decode_batch((x,y))\n",
    "s\n",
    "test_eq(type(s[0][1]), fastuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T09:40:10.625186Z",
     "start_time": "2021-01-29T09:40:10.602724Z"
    }
   },
   "outputs": [],
   "source": [
    "it = iter(tdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T09:40:11.533792Z",
     "start_time": "2021-01-29T09:40:11.402877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), (tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3])))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T09:40:19.948235Z",
     "start_time": "2021-01-29T09:40:19.940356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 5, 6, 7]), (tensor([4, 5, 6, 7]), tensor([4, 5, 6, 7])))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T03:28:07.624700Z",
     "start_time": "2021-01-31T03:28:07.072042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TfmdDL at 0x7fda20b2e670>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#1) [tensor([-2, -4, -6, -8])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdl = TfmdDL([1,2,3,4,5], after_item=lambda o : o*2, after_batch=lambda i: -i, bs=4,drop_last=True)\n",
    "tdl\n",
    "L(tdl)\n",
    "# tdl.show_batch()\n",
    "# 此处无法使用show_batch, 因为无法对tensor使用这个功能,不过下面的代码中,经过A函数编码之后,输出了一个list,可以进行show功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T03:15:24.803279Z",
     "start_time": "2021-01-31T03:15:24.798071Z"
    }
   },
   "outputs": [],
   "source": [
    "aa = [1,2,3]\n",
    "bb = L(1,2,3)\n",
    "test_eq(aa,bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T03:19:31.612538Z",
     "start_time": "2021-01-31T03:19:31.607770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = A()\n",
    "temp(aa)\n",
    "type(temp(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T03:25:45.141856Z",
     "start_time": "2021-01-31T03:25:44.951861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#13) [tensor([0, 1, 2, 3]),tensor([4, 5, 6, 7]),tensor([ 8,  9, 10, 11]),tensor([12, 13, 14, 15]),tensor([16, 17, 18, 19]),tensor([20, 21, 22, 23]),tensor([24, 25, 26, 27]),tensor([28, 29, 30, 31]),tensor([32, 33, 34, 35]),tensor([36, 37, 38, 39])...]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tdl = TfmdDL(torch.arange(0,50), after_item=A(),  bs=4)\n",
    "tdl.dataset\n",
    "tdl.dataset[0]\n",
    "L(tdl)\n",
    "tdl.show_batch()\n",
    "test_eq(tdl.dataset[0], start[0])\n",
    "test_eq(len(tdl), (50-1)//4+1)\n",
    "test_eq(tdl.bs, 4)\n",
    "test_stdout(tdl.show_batch, '0\\n1\\n2\\n3')\n",
    "test_stdout(partial(tdl.show_batch, unique=True), '0\\n0\\n0\\n0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T03:15:25.543455Z",
     "start_time": "2021-01-31T03:15:25.357731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TfmdDL at 0x7fda2052fd90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#13) [tensor([ 0, -1, -2, -3]),tensor([-4, -5, -6, -7]),tensor([ -8,  -9, -10, -11]),tensor([-12, -13, -14, -15]),tensor([-16, -17, -18, -19]),tensor([-20, -21, -22, -23]),tensor([-24, -25, -26, -27]),tensor([-28, -29, -30, -31]),tensor([-32, -33, -34, -35]),tensor([-36, -37, -38, -39])...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tdl\n",
    "tdl.dataset\n",
    "len(tdl)\n",
    "L(tdl)\n",
    "tdl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T04:21:47.807914Z",
     "start_time": "2021-01-31T04:21:47.803796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T04:38:11.247585Z",
     "start_time": "2021-01-31T04:38:11.242411Z"
    }
   },
   "outputs": [],
   "source": [
    "NegTfm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T04:41:57.482657Z",
     "start_time": "2021-01-31T04:41:57.479107Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T04:42:32.205720Z",
     "start_time": "2021-01-31T04:42:32.200783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T04:42:13.614455Z",
     "start_time": "2021-01-31T04:42:13.599172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TfmdDL at 0x7fda21023640>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline: B -> NegTfm"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [B:\n",
       "encodes: (object,object) -> encodes\n",
       "decodes: ,NegTfm:\n",
       "encodes: (object,object) -> encodes\n",
       "decodes: (object,object) -> decodes\n",
       "]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TfmdDL at 0x7fda21023640>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class B(Transform):\n",
    "    parameters = 'a'\n",
    "    def __init__(self): self.a = torch.tensor(0.)\n",
    "    def encodes(self, x): x\n",
    "\n",
    "tdl = TfmdDL([(TensorImage([1]),)] * 4, after_batch=[B(),NegTfm()], bs=4)\n",
    "tdl\n",
    "tdl.after_batch\n",
    "# fs means functions \n",
    "tdl.after_batch.fs\n",
    "tdl.after_batch.fs[0].a.device\n",
    "test_eq(tdl.after_batch.fs[0].a.device, torch.device('cpu'))\n",
    "tdl.to(default_device())\n",
    "test_eq(tdl.after_batch.fs[0].a.device, default_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T04:22:59.951740Z",
     "start_time": "2021-01-31T04:22:59.946456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function fastai.data.load.DataLoader.one_batch(self)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TfmdDL.one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:34:14.147284Z",
     "start_time": "2021-01-31T06:34:14.144308Z"
    }
   },
   "outputs": [],
   "source": [
    "tfm = NegTfm()\n",
    "tdl = TfmdDL(start, after_batch=tfm, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:34:18.201476Z",
     "start_time": "2021-01-31T06:34:18.195937Z"
    }
   },
   "outputs": [],
   "source": [
    "b = tdl.one_batch()\n",
    "test_eq(tensor([0,-1,-2,-3]), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:34:38.563343Z",
     "start_time": "2021-01-31T06:34:38.557447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TfmdDL.decode(self, b)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TfmdDL.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:34:45.449631Z",
     "start_time": "2021-01-31T06:34:45.445732Z"
    }
   },
   "outputs": [],
   "source": [
    "test_eq(tdl.decode(b), tensor(0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:37:56.465822Z",
     "start_time": "2021-01-31T06:37:56.460470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TfmdDL.decode_batch(self, b, max_n=9, full=True)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TfmdDL.decode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:37:56.763164Z",
     "start_time": "2021-01-31T06:37:56.757300Z"
    }
   },
   "outputs": [],
   "source": [
    "test_eq(tdl.decode_batch(b), [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:37:59.459112Z",
     "start_time": "2021-01-31T06:37:59.453569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TfmdDL.show_batch(self, b=None, max_n=9, ctxs=None, show=True, unique=False, **kwargs)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TfmdDL.show_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:38:02.050533Z",
     "start_time": "2021-01-31T06:38:02.044887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TfmdDL.to(self, device)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TfmdDL.to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处的dataloaders不同于上一章节中的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:39:43.656355Z",
     "start_time": "2021-01-31T06:39:43.645633Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataLoaders(GetAttr):\n",
    "    \"Basic wrapper around several `DataLoader`s.\"\n",
    "    _default='train'\n",
    "    def __init__(self, *loaders, path='.', device=None):\n",
    "        self.loaders,self.path = list(loaders),Path(path)\n",
    "        if device is not None or hasattr(loaders[0],'to'): self.device = device\n",
    "\n",
    "    def __getitem__(self, i): return self.loaders[i]\n",
    "    def new_empty(self):\n",
    "        loaders = [dl.new(dl.dataset.new_empty()) for dl in self.loaders]\n",
    "        return type(self)(*loaders, path=self.path, device=self.device)\n",
    "\n",
    "    def _set(i, self, v): self.loaders[i] = v\n",
    "    train   ,valid    = add_props(lambda i,x: x[i], _set)\n",
    "    train_ds,valid_ds = add_props(lambda i,x: x[i].dataset)\n",
    "\n",
    "    @property\n",
    "    def device(self): return self._device\n",
    "\n",
    "    @device.setter\n",
    "    def device(self, d):\n",
    "        for dl in self.loaders: dl.to(d)\n",
    "        self._device = d\n",
    "\n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        return self\n",
    "\n",
    "    def cuda(self): return self.to(device=default_device())\n",
    "    def cpu(self):  return self.to(device=torch.device('cpu'))\n",
    "\n",
    "    @classmethod\n",
    "    def from_dsets(cls, *ds, path='.',  bs=64, device=None, dl_type=TfmdDL, **kwargs):\n",
    "        default = (True,) + (False,) * (len(ds)-1)\n",
    "        defaults = {'shuffle': default, 'drop_last': default}\n",
    "        for nm in _batch_tfms:\n",
    "            if nm in kwargs: kwargs[nm] = Pipeline(kwargs[nm])\n",
    "        kwargs = merge(defaults, {k: tuplify(v, match=ds) for k,v in kwargs.items()})\n",
    "        kwargs = [{k: v[i] for k,v in kwargs.items()} for i in range_of(ds)]\n",
    "        return cls(*[dl_type(d, bs=bs, **k) for d,k in zip(ds, kwargs)], path=path, device=device)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dblock(cls, dblock, source, path='.',  bs=64, val_bs=None, shuffle_train=True, device=None, **kwargs):\n",
    "        return dblock.dataloaders(source, path=path, bs=bs, val_bs=val_bs, shuffle_train=shuffle_train, device=device, **kwargs)\n",
    "\n",
    "    _docs=dict(__getitem__=\"Retrieve `DataLoader` at `i` (`0` is training, `1` is validation)\",\n",
    "               train=\"Training `DataLoader`\",\n",
    "               valid=\"Validation `DataLoader`\",\n",
    "               train_ds=\"Training `Dataset`\",\n",
    "               valid_ds=\"Validation `Dataset`\",\n",
    "               to=\"Use `device`\",\n",
    "               cuda=\"Use the gpu if available\",\n",
    "               cpu=\"Use the cpu\",\n",
    "               new_empty=\"Create a new empty version of `self` with the same transforms\",\n",
    "               from_dblock=\"Create a dataloaders from a given `dblock`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:39:56.339271Z",
     "start_time": "2021-01-31T06:39:56.333848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -1, -2, -3])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:44:47.038624Z",
     "start_time": "2021-01-31T06:44:46.077596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TfmdDL at 0x7fda0dfd81f0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -1, -2, -3])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -1, -2, -3])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders(tdl,tdl)\n",
    "dls.train\n",
    "x = dls.train.one_batch()\n",
    "x\n",
    "x2 = first(tdl)\n",
    "test_eq(x,x2)\n",
    "x2 = dls.one_batch()\n",
    "x2\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:45:21.090826Z",
     "start_time": "2021-01-31T06:45:21.087319Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#test assignment works\n",
    "dls.train = dls.train.new(bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:50:14.682302Z",
     "start_time": "2021-01-31T06:50:14.677613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TfmdDL at 0x7fda212a89d0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:49:54.617662Z",
     "start_time": "2021-01-31T06:49:54.611482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:50:01.420872Z",
     "start_time": "2021-01-31T06:50:01.412949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:13.038144Z",
     "start_time": "2021-01-29T08:09:13.025168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataLoaders.__getitem__\" class=\"doc_header\"><code>DataLoaders.__getitem__</code><a href=\"__main__.py#L10\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataLoaders.__getitem__</code>(**`i`**)\n",
       "\n",
       "Retrieve [`DataLoader`](/data.load#DataLoader) at `i` (`0` is training, `1` is validation)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(DataLoaders.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:47:28.661453Z",
     "start_time": "2021-01-31T06:47:28.655950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TfmdDL at 0x7fda212a89d0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TfmdDL at 0x7fda0dfd81f0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls[0]\n",
    "dls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:47:32.550697Z",
     "start_time": "2021-01-31T06:47:32.545623Z"
    }
   },
   "outputs": [],
   "source": [
    "x2 = dls[0].one_batch()\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdLists -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:48:39.005126Z",
     "start_time": "2021-01-31T06:48:38.990492Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class FilteredBase:\n",
    "    \"Base class for lists with subsets\"\n",
    "    _dl_type,_dbunch_type = TfmdDL,DataLoaders\n",
    "    def __init__(self, *args, dl_type=None, **kwargs):\n",
    "        if dl_type is not None: self._dl_type = dl_type\n",
    "        self.dataloaders = delegates(self._dl_type.__init__)(self.dataloaders)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def n_subsets(self): return len(self.splits)\n",
    "    def _new(self, items, **kwargs): return super()._new(items, splits=self.splits, **kwargs)\n",
    "    def subset(self): raise NotImplemented\n",
    "\n",
    "    def dataloaders(self, bs=64, val_bs=None, shuffle_train=True, n=None, path='.', dl_type=None, dl_kwargs=None,\n",
    "                    device=None, **kwargs):\n",
    "        if device is None: device=default_device()\n",
    "        if dl_kwargs is None: dl_kwargs = [{}] * self.n_subsets\n",
    "        if dl_type is None: dl_type = self._dl_type\n",
    "        drop_last = kwargs.pop('drop_last', shuffle_train)\n",
    "        dl = dl_type(self.subset(0), bs=bs, shuffle=shuffle_train, drop_last=drop_last, n=n, device=device,\n",
    "                     **merge(kwargs, dl_kwargs[0]))\n",
    "        dls = [dl] + [dl.new(self.subset(i), bs=(bs if val_bs is None else val_bs), shuffle=False, drop_last=False,\n",
    "                             n=None, **dl_kwargs[i]) for i in range(1, self.n_subsets)]\n",
    "        return self._dbunch_type(*dls, path=path, device=device)\n",
    "\n",
    "FilteredBase.train,FilteredBase.valid = add_props(lambda i,x: x.subset(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:48:39.790947Z",
     "start_time": "2021-01-31T06:48:39.767238Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class TfmdLists(FilteredBase, L, GetAttr):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of `items`\"\n",
    "    _default='tfms'\n",
    "    def __init__(self, items, tfms, use_list=None, do_setup=True, split_idx=None, train_setup=True,\n",
    "                 splits=None, types=None, verbose=False, dl_type=None):\n",
    "        super().__init__(items, use_list=use_list)\n",
    "        if dl_type is not None: self._dl_type = dl_type\n",
    "        self.splits = L([slice(None),[]] if splits is None else splits).map(mask2idxs)\n",
    "        if isinstance(tfms,TfmdLists): tfms = tfms.tfms\n",
    "        if isinstance(tfms,Pipeline): do_setup=False\n",
    "        self.tfms = Pipeline(tfms, split_idx=split_idx)\n",
    "        store_attr('types,split_idx')\n",
    "        if do_setup:\n",
    "            pv(f\"Setting up {self.tfms}\", verbose)\n",
    "            self.setup(train_setup=train_setup)\n",
    "\n",
    "    def _new(self, items, split_idx=None, **kwargs):\n",
    "        split_idx = ifnone(split_idx,self.split_idx)\n",
    "        return super()._new(items, tfms=self.tfms, do_setup=False, types=self.types, split_idx=split_idx, **kwargs)\n",
    "    def subset(self, i): return self._new(self._get(self.splits[i]), split_idx=i)\n",
    "    def _after_item(self, o): return self.tfms(o)\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms.fs}\"\n",
    "    def __iter__(self): return (self[i] for i in range(len(self)))\n",
    "    def show(self, o, **kwargs): return self.tfms.show(o, **kwargs)\n",
    "    def decode(self, o, **kwargs): return self.tfms.decode(o, **kwargs)\n",
    "    def __call__(self, o, **kwargs): return self.tfms.__call__(o, **kwargs)\n",
    "    def overlapping_splits(self): return L(Counter(self.splits.concat()).values()).filter(gt(1))\n",
    "    def new_empty(self): return self._new([])\n",
    "\n",
    "    def setup(self, train_setup=True):\n",
    "        self.tfms.setup(self, train_setup)\n",
    "        if len(self) != 0:\n",
    "            x = super().__getitem__(0) if self.splits is None else super().__getitem__(self.splits[0])[0]\n",
    "            self.types = []\n",
    "            for f in self.tfms.fs:\n",
    "                self.types.append(getattr(f, 'input_types', type(x)))\n",
    "                x = f(x)\n",
    "            self.types.append(type(x))\n",
    "        types = L(t if is_listy(t) else [t] for t in self.types).concat().unique()\n",
    "        self.pretty_types = '\\n'.join([f'  - {t}' for t in types])\n",
    "\n",
    "    def infer_idx(self, x):\n",
    "        # TODO: check if we really need this, or can simplify\n",
    "        idx = 0\n",
    "        for t in self.types:\n",
    "            if isinstance(x, t): break\n",
    "            idx += 1\n",
    "        types = L(t if is_listy(t) else [t] for t in self.types).concat().unique()\n",
    "        pretty_types = '\\n'.join([f'  - {t}' for t in types])\n",
    "        assert idx < len(self.types), f\"Expected an input of type in \\n{pretty_types}\\n but got {type(x)}\"\n",
    "        return idx\n",
    "\n",
    "    def infer(self, x):\n",
    "        return compose_tfms(x, tfms=self.tfms.fs[self.infer_idx(x):], split_idx=self.split_idx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = super().__getitem__(idx)\n",
    "        if self._after_item is None: return res\n",
    "        return self._after_item(res) if is_indexer(idx) else res.map(self._after_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:48:40.564003Z",
     "start_time": "2021-01-31T06:48:40.558165Z"
    }
   },
   "source": [
    "\n",
    "(TfmdLists,\n",
    "         setup=\"Transform setup with self\",\n",
    "         decode=\"From `Pipeline`\",\n",
    "         show=\"From `Pipeline`\",\n",
    "         overlapping_splits=\"All splits that are in more than one split\",\n",
    "         subset=\"New `TfmdLists` with same tfms that only includes items in `i`th split\",\n",
    "         infer_idx=\"Finds the index where `self.tfms` can be applied to `x`, depending on the type of `x`\",\n",
    "         infer=\"Apply `self.tfms` to `x` starting at the right tfm depending on the type of `x`\",\n",
    "         new_empty=\"A new version of `self` but with no items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:13.107661Z",
     "start_time": "2021-01-29T08:09:13.102822Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def decode_at(o, idx):\n",
    "    \"Decoded item at `idx`\"\n",
    "    return o.decode(o[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:13.114212Z",
     "start_time": "2021-01-29T08:09:13.109137Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_at(o, idx, **kwargs):\n",
    "    \"Show item at `idx`\",\n",
    "    return o.show(o[idx], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TfmdLists` combines a collection of object with a `Pipeline`. `tfms` can either be a `Pipeline` or a list of transforms, in which case, it will wrap them in a `Pipeline`. `use_list` is passed along to `L` with the `items` and `split_idx` are passed to each transform of the `Pipeline`. `do_setup` indicates if the `Pipeline.setup` method should be called during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:54:37.589388Z",
     "start_time": "2021-01-31T06:54:37.575372Z"
    }
   },
   "outputs": [],
   "source": [
    "TitledInt??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:54:37.896833Z",
     "start_time": "2021-01-31T06:54:37.890111Z"
    }
   },
   "outputs": [],
   "source": [
    "class _IntFloatTfm(Transform):\n",
    "    def encodes(self, o):  return TitledInt(o)\n",
    "    def decodes(self, o):  return TitledFloat(o)\n",
    "int2f_tfm=_IntFloatTfm()\n",
    "\n",
    "def _neg(o): return -o\n",
    "neg_tfm = Transform(_neg, _neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T06:57:03.393081Z",
     "start_time": "2021-01-31T06:57:03.387883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = neg_tfm(2)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:33:43.204225Z",
     "start_time": "2021-01-31T08:33:43.197010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdLists: [1.0, 2.0, 3.0]\n",
       "tfms - [_neg:\n",
       "encodes: (object,object) -> _negdecodes: (object,object) -> _neg, _IntFloatTfm:\n",
       "encodes: (object,object) -> encodes\n",
       "decodes: (object,object) -> decodes\n",
       "]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = L([1.,2.,3.]); tfms = [neg_tfm, int2f_tfm]\n",
    "tl = TfmdLists(items, tfms=tfms)\n",
    "test_eq_type(tl[0], TitledInt(-1))\n",
    "test_eq_type(tl[1], TitledInt(-2))\n",
    "test_eq_type(tl.decode(tl[2]), TitledFloat(3.))\n",
    "test_stdout(lambda: show_at(tl, 2), '-3')\n",
    "test_eq(tl.types, [float, float, TitledInt])\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:33:43.960734Z",
     "start_time": "2021-01-31T08:33:43.948045Z"
    }
   },
   "outputs": [],
   "source": [
    "# add splits to TfmdLists\n",
    "splits = [[0,2],[1]]\n",
    "tl = TfmdLists(items, tfms=tfms, splits=splits)\n",
    "test_eq(tl.n_subsets, 2)\n",
    "test_eq(tl.train, tl.subset(0))\n",
    "test_eq(tl.valid, tl.subset(1))\n",
    "test_eq(tl.train.items, items[splits[0]])\n",
    "test_eq(tl.valid.items, items[splits[1]])\n",
    "test_eq(tl.train.tfms.split_idx, 0)\n",
    "test_eq(tl.valid.tfms.split_idx, 1)\n",
    "test_eq(tl.train.new_empty().split_idx, 0)\n",
    "test_eq(tl.valid.new_empty().split_idx, 1)\n",
    "test_eq_type(tl.splits, L(splits))\n",
    "assert not tl.overlapping_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:33:44.981177Z",
     "start_time": "2021-01-31T08:33:44.964753Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(a=[1,2,3],b=[2,3,4]))\n",
    "tl = TfmdLists(df, lambda o: o.a+1, splits=[[0],[1,2]])\n",
    "test_eq(tl[1,2], [3,4])\n",
    "tr = tl.subset(0)\n",
    "test_eq(tr[:], [2])\n",
    "val = tl.subset(1)\n",
    "test_eq(val[:], [3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:33:45.354729Z",
     "start_time": "2021-01-31T08:33:45.348486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [1.0,2.0,3.0]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:33:46.568580Z",
     "start_time": "2021-01-31T08:33:46.558264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfmdLists: [1.0, 2.0, 3.0]\n",
      "tfms - []\n"
     ]
    }
   ],
   "source": [
    "class _B(Transform):\n",
    "    def __init__(self): self.m = 0\n",
    "    def encodes(self, o): return o+self.m\n",
    "    def decodes(self, o): return o-self.m\n",
    "    def setups(self, items): \n",
    "        print(items)\n",
    "        self.m = tensor(items).float().mean().item()\n",
    "\n",
    "# test for setup, which updates `self.m`\n",
    "tl = TfmdLists(items, _B())\n",
    "test_eq(tl.m, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdLists.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:05.915184Z",
     "start_time": "2021-01-31T07:55:05.900766Z"
    }
   },
   "outputs": [],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def encodes(self, o):    return int(self.o2i[o])\n",
    "    def decodes(self, o):    return TitledStr(self.vocab[o])\n",
    "    def setups(self, items): self.vocab,self.o2i = uniqueify(L(items), sort=True, bidir=True)\n",
    "tcat = _Cat()\n",
    "\n",
    "def _lbl(o): return TitledStr(o.split('_')[0])\n",
    "\n",
    "# Check that tfms are sorted by `order` & `_lbl` is called first\n",
    "fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tl = TfmdLists(fns, [tcat,_lbl])\n",
    "exp_voc = ['cat','dog']\n",
    "test_eq(tcat.vocab, exp_voc)\n",
    "test_eq(tl.tfms.vocab, exp_voc)\n",
    "test_eq(tl.vocab, exp_voc)\n",
    "test_eq(tl, (1,0,0,0,1))\n",
    "test_eq([tl.decode(o) for o in tl], ('dog','cat','cat','cat','dog'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:07.156632Z",
     "start_time": "2021-01-31T07:55:07.148431Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check only the training set is taken into account for setup\n",
    "tl = TfmdLists(fns, [tcat,_lbl], splits=[[0,4], [1,2,3]])\n",
    "test_eq(tcat.vocab, ['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:14.003897Z",
     "start_time": "2021-01-31T07:55:13.989141Z"
    }
   },
   "outputs": [],
   "source": [
    "tfm = NegTfm(split_idx=1)\n",
    "tds = TfmdLists(start, A())\n",
    "tdl = TfmdDL(tds, after_batch=tfm, bs=4)\n",
    "x = tdl.one_batch()\n",
    "test_eq(x, torch.arange(4))\n",
    "tds.split_idx = 1\n",
    "x = tdl.one_batch()\n",
    "test_eq(x, -torch.arange(4))\n",
    "tds.split_idx = 0\n",
    "x = tdl.one_batch()\n",
    "test_eq(x, torch.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:14.873483Z",
     "start_time": "2021-01-31T07:55:14.862163Z"
    }
   },
   "outputs": [],
   "source": [
    "tds = TfmdLists(start, A())\n",
    "tdl = TfmdDL(tds, after_batch=NegTfm(), bs=4)\n",
    "test_eq(tdl.dataset[0], start[0])\n",
    "test_eq(len(tdl), (len(tds)-1)//4+1)\n",
    "test_eq(tdl.bs, 4)\n",
    "test_stdout(tdl.show_batch, '0\\n1\\n2\\n3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:15.713031Z",
     "start_time": "2021-01-31T07:55:15.708637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TfmdLists.subset(self, i)>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TfmdLists.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:16.443048Z",
     "start_time": "2021-01-31T07:55:16.438534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TfmdLists.infer_idx(self, x)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TfmdLists.infer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:17.027449Z",
     "start_time": "2021-01-31T07:55:17.021481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.TfmdLists.infer(self, x)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TfmdLists.infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:35.911736Z",
     "start_time": "2021-01-31T07:55:35.901941Z"
    }
   },
   "outputs": [],
   "source": [
    "def mult(x): return x*2\n",
    "mult.order = 2\n",
    "\n",
    "fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tl = TfmdLists(fns, [_lbl,_Cat(),mult])\n",
    "\n",
    "test_eq(tl.infer_idx('dog_45.jpg'), 0)\n",
    "test_eq(tl.infer('dog_45.jpg'), 2)\n",
    "\n",
    "test_eq(tl.infer_idx(4), 2)\n",
    "test_eq(tl.infer(4), 8)\n",
    "\n",
    "test_fail(lambda: tl.infer_idx(2.0))\n",
    "test_fail(lambda: tl.infer(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T07:55:36.247703Z",
     "start_time": "2021-01-31T07:55:36.232803Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Test input_types works on a Transform\n",
    "cat = _Cat()\n",
    "cat.input_types = (str, float)\n",
    "tl = TfmdLists(fns, [_lbl,cat,mult])\n",
    "test_eq(tl.infer_idx(2.0), 1)\n",
    "\n",
    "#Test type annotations work on a function\n",
    "def mult(x:(int,float)): return x*2\n",
    "mult.order = 2\n",
    "tl = TfmdLists(fns, [_lbl,_Cat(),mult])\n",
    "test_eq(tl.infer_idx(2.0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:13.337174Z",
     "start_time": "2021-01-29T08:09:13.256771Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@delegates(TfmdLists)\n",
    "class Datasets(FilteredBase):\n",
    "    \"A dataset that creates a tuple from each `tfms`, passed through `item_tfms`\"\n",
    "    def __init__(self, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, **kwargs):\n",
    "        super().__init__(dl_type=dl_type)\n",
    "        self.tls = L(tls if tls else [TfmdLists(items, t, **kwargs) for t in L(ifnone(tfms,[None]))])\n",
    "        self.n_inp = ifnone(n_inp, max(1, len(self.tls)-1))\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        res = tuple([tl[it] for tl in self.tls])\n",
    "        return res if is_indexer(it) else list(zip(*res))\n",
    "\n",
    "    def __getattr__(self,k): return gather_attrs(self, k, 'tls')\n",
    "    def __dir__(self): return super().__dir__() + gather_attr_names(self, 'tls')\n",
    "    def __len__(self): return len(self.tls[0])\n",
    "    def __iter__(self): return (self[i] for i in range(len(self)))\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    def decode(self, o, full=True): return tuple(tl.decode(o_, full=full) for o_,tl in zip(o,tuplify(self.tls, match=o)))\n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp)\n",
    "    def _new(self, items, *args, **kwargs): return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "    def overlapping_splits(self): return self.tls[0].overlapping_splits()\n",
    "    def new_empty(self): return type(self)(tls=[tl.new_empty() for tl in self.tls], n_inp=self.n_inp)\n",
    "    @property\n",
    "    def splits(self): return self.tls[0].splits\n",
    "    @property\n",
    "    def split_idx(self): return self.tls[0].tfms.split_idx\n",
    "    @property\n",
    "    def items(self): return self.tls[0].items\n",
    "    @items.setter\n",
    "    def items(self, v):\n",
    "        for tl in self.tls: tl.items = v\n",
    "\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for o_,tl in zip(o,self.tls): ctx = tl.show(o_, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    @contextmanager\n",
    "    def set_split_idx(self, i):\n",
    "        old_split_idx = self.split_idx\n",
    "        for tl in self.tls: tl.tfms.split_idx = i\n",
    "        try: yield self\n",
    "        finally:\n",
    "            for tl in self.tls: tl.tfms.split_idx = old_split_idx\n",
    "\n",
    "    _docs=dict(\n",
    "        decode=\"Compose `decode` of all `tuple_tfms` then all `tfms` on `i`\",\n",
    "        show=\"Show item `o` in `ctx`\",\n",
    "        dataloaders=\"Get a `DataLoaders`\",\n",
    "        overlapping_splits=\"All splits that are in more than one split\",\n",
    "        subset=\"New `Datasets` that only includes subset `i`\",\n",
    "        new_empty=\"Create a new empty version of the `self`, keeping only the transforms\",\n",
    "        set_split_idx=\"Contextmanager to use the same `Datasets` with another `split_idx`\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Datasets` creates a tuple from `items` (typically input,target) by applying to them each list of `Transform` (or `Pipeline`) in `tfms`. Note that if `tfms` contains only one list of `tfms`, the items given by `Datasets` will be tuples of one element. \n",
    "\n",
    "`n_inp` is the number of elements in the tuples that should be considered part of the input and will default to 1 if `tfms` consists of one set of transforms, `len(tfms)-1` otherwise. In most cases, the number of elements in the tuples spit out by `Datasets` will be 2 (for input,target) but it can happen that there is 3 (Siamese networks or tabular data) in which case we need to be able to determine when the inputs end and the targets begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:18:01.605326Z",
     "start_time": "2021-01-31T08:18:01.601721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function fastcore.basics._oper.<locals>.<lambda>(o)>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:26:12.569097Z",
     "start_time": "2021-01-31T08:26:12.554443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [(-1, 2),(-2, 3),(-3, 4),(-4, 5)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items =[1,2,3,4]\n",
    "# 下面定义了两组变换形式, 求负数与类型转换+加一的操作\n",
    "dsets = Datasets(items, [[neg_tfm,int2f_tfm], [add(1)]])\n",
    "dsets\n",
    "t = dsets[0]\n",
    "test_eq(t, (-1,2))\n",
    "test_eq(dsets[0,1,2], [(-1,2),(-2,3),(-3,4)])\n",
    "test_eq(dsets.n_inp, 1)\n",
    "dsets.decode(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm变换example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:28:55.079769Z",
     "start_time": "2021-01-31T08:28:55.074989Z"
    }
   },
   "outputs": [],
   "source": [
    "class Norm(Transform):\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setups(self, items):\n",
    "        its = tensor(items).float()\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:40:36.642633Z",
     "start_time": "2021-01-31T08:40:36.610382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [(-1, tensor(1.1619)),(-2, tensor(0.3873)),(-3, tensor(-0.3873)),(-4, tensor(-1.1619))]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-1, -2, -3, -4)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.1619), tensor(0.3873), tensor(-0.3873), tensor(-1.1619))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(-2.5000)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [1,2,3,4]\n",
    "nrm = Norm()\n",
    "dsets = Datasets(items, [[neg_tfm,int2f_tfm], [neg_tfm,nrm]])\n",
    "\n",
    "dsets\n",
    "x,y = zip(*dsets)\n",
    "x\n",
    "y\n",
    "# 实行变换后,可以直接从子类中取出mean这个属性值\n",
    "nrm.m\n",
    "\n",
    "\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, (-1,-2,-3,-4,))\n",
    "test_eq(nrm.m, -2.5)\n",
    "test_stdout(lambda:show_at(dsets, 1), '-2')\n",
    "\n",
    "test_eq(dsets.m, nrm.m)\n",
    "test_eq(dsets.norm.m, nrm.m)\n",
    "test_eq(dsets.train.norm.m, nrm.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:13.396368Z",
     "start_time": "2021-01-29T08:09:13.387556Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Check filtering is properly applied\n",
    "class B(Transform):\n",
    "    def encodes(self, x)->None:  return int(x+1)\n",
    "    def decodes(self, x):        return TitledInt(x-1)\n",
    "add1 = B(split_idx=1)\n",
    "\n",
    "dsets = Datasets(items, [neg_tfm, [neg_tfm,int2f_tfm,add1]], splits=[[3],[0,1,2]])\n",
    "test_eq(dsets[1], [-2,-2])\n",
    "test_eq(dsets.valid[1], [-2,-1])\n",
    "test_eq(dsets.valid[[1,1]], [[-2,-1], [-2,-1]])\n",
    "test_eq(dsets.train[0], [-4,-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:42:32.117790Z",
     "start_time": "2021-01-31T08:42:32.111928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_Cat:\n",
       "encodes: (object,object) -> encodes\n",
       "decodes: (object,object) -> decodes"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_Cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:44:58.083630Z",
     "start_time": "2021-01-31T08:44:58.071182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [(1,),(0,),(0,)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','kid_1.jpg']\n",
    "tcat = _Cat()\n",
    "dsets = Datasets(test_fns, [[tcat,_lbl]], splits=[[0,1,2], [3,4]])\n",
    "\n",
    "dsets.train\n",
    "dsets.valid[0]\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq(dsets.train, [(1,),(0,),(0,)])\n",
    "test_eq(dsets.valid[0], (0,))\n",
    "test_stdout(lambda: show_at(dsets.train, 0), \"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:47:16.767796Z",
     "start_time": "2021-01-31T08:47:16.754578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [(0,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = [0,1,2,3,4]\n",
    "dsets = Datasets(inp, tfms=[None])\n",
    "\n",
    "dsets\n",
    "dsets[2]\n",
    "\n",
    "test_eq(*dsets[2], 2)          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsets[1,2], [(1,),(2,)])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsets[mask], [(0,),(3,)])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:49:30.073310Z",
     "start_time": "2021-01-31T08:49:30.052010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a\n",
       "0  5\n",
       "1  1\n",
       "2  2\n",
       "3  3\n",
       "4  4"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [(5,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = pd.DataFrame(dict(a=[5,1,2,3,4]))\n",
    "dsets = Datasets(inp, tfms=attrgetter('a')).subset(0)\n",
    "\n",
    "inp\n",
    "dsets\n",
    "\n",
    "\n",
    "test_eq(*dsets[2], 2)          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsets[1,2], [(1,),(2,)])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsets[mask], [(5,),(3,)])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T08:56:17.460335Z",
     "start_time": "2021-01-31T08:56:17.433373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [(0,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [(0,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [(0, 0, 0),(1, 1, 1),(2, 2, 2),(3, 3, 3),(4, 4, 4)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [(0, 0),(1, 1),(2, 2),(3, 3),(4, 4)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [(0, 0, 0),(1, 1, 1),(2, 2, 2),(3, 3, 3),(4, 4, 4)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test n_inp\n",
    "inp = [0,1,2,3,4]\n",
    "dsets = Datasets(inp)\n",
    "dsets\n",
    "dsets.n_inp\n",
    "\n",
    "dsets = Datasets(inp, tfms=[None])\n",
    "\n",
    "dsets\n",
    "\n",
    "test_eq(dsets.n_inp, 1)\n",
    "dsets = Datasets(inp, tfms=[[None],[None],[None]])\n",
    "\n",
    "dsets\n",
    "\n",
    "\n",
    "test_eq(dsets.n_inp, 2)\n",
    "\n",
    "dsets = Datasets(inp, tfms=[[None],[None]])\n",
    "dsets\n",
    "dsets.n_inp\n",
    "\n",
    "dsets = Datasets(inp, tfms=[[None],[None],[None]], n_inp=1)\n",
    "\n",
    "\n",
    "dsets\n",
    "test_eq(dsets.n_inp, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:02:28.339391Z",
     "start_time": "2021-01-31T09:02:28.322541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [(0,),(2,)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [(1,),(3,),(4,)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splits can be indices\n",
    "dsets = Datasets(range(5), tfms=[None], splits=[tensor([0,2]), [1,3,4]])\n",
    "# dsets\n",
    "dsets.train\n",
    "dsets.valid\n",
    "\n",
    "test_eq(dsets.subset(0), [(0,),(2,)])\n",
    "test_eq(dsets.train, [(0,),(2,)])       # Subset 0 is aliased to `train`\n",
    "test_eq(dsets.subset(1), [(1,),(3,),(4,)])\n",
    "test_eq(dsets.valid, [(1,),(3,),(4,)])     # Subset 1 is aliased to `valid`\n",
    "test_eq(*dsets.valid[2], 4)\n",
    "#assert '[(1,),(3,),(4,)]' in str(dsets) and '[(0,),(2,)]' in str(dsets)\n",
    "# dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:13.465181Z",
     "start_time": "2021-01-29T08:09:13.460294Z"
    }
   },
   "outputs": [],
   "source": [
    "# splits can be boolean masks (they don't have to cover all items, but must be disjoint)\n",
    "splits = [[False,True,True,False,True], [True,False,False,False,False]]\n",
    "dsets = Datasets(range(5), tfms=[None], splits=splits)\n",
    "\n",
    "test_eq(dsets.train, [(1,),(2,),(4,)])\n",
    "test_eq(dsets.valid, [(0,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:03:50.259615Z",
     "start_time": "2021-01-31T09:03:50.248757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [(1,),(3,),(5,),(7,),(9,)]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply transforms to all items\n",
    "tfm = [[lambda x: x*2,lambda x: x+1]]\n",
    "splits = [[1,2],[0,3,4]]\n",
    "dsets = Datasets(range(5), tfm, splits=splits)\n",
    "dsets\n",
    "\n",
    "test_eq(dsets.train,[(3,),(5,)])\n",
    "test_eq(dsets.valid,[(1,),(7,),(9,)])\n",
    "test_eq(dsets.train[False,True], [(5,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.loli.net/2021/01/31/FsWpz2ImgnHyU9a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:20:04.109774Z",
     "start_time": "2021-01-31T09:20:04.105832Z"
    }
   },
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm(Transform):\n",
    "    split_idx=1\n",
    "    def encodes(self, x): return x*2\n",
    "    def decodes(self, x): return TitledStr(x//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:15:27.709577Z",
     "start_time": "2021-01-31T09:15:27.702038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [tensor([0, 1]),tensor([2, 3]),tensor([4])]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = DataLoader(range(5),bs = 2,after_item=_Tfm())\n",
    "L(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:20:05.922132Z",
     "start_time": "2021-01-31T09:20:05.914527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [(0,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets = Datasets(range(5), [_Tfm()])\n",
    "dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:20:45.634355Z",
     "start_time": "2021-01-31T09:20:45.620929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [(0,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [(0,),(1,),(2,),(3,),(4,)]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets = Datasets(range(5), [_Tfm()], splits=[[1,2],[0,3,4]])\n",
    "dsets\n",
    "# 注意此处的dsets没有发生转换, 反而单独拿出来valid有了变化\n",
    "test_eq(dsets.train,[(1,),(2,)])\n",
    "test_eq(dsets.valid,[(0,),(6,),(8,)])\n",
    "test_eq(dsets.train[False,True], [(2,)])\n",
    "dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:22:30.322790Z",
     "start_time": "2021-01-31T09:22:30.313842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [(1,),(2,)]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A context manager to change the split_idx and apply the validation transform on the training set\n",
    "ds = dsets.train\n",
    "ds\n",
    "with ds.set_split_idx(1):\n",
    "    test_eq(ds,[(2,),(4,)])\n",
    "test_eq(dsets.train,[(1,),(2,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:13.513178Z",
     "start_time": "2021-01-29T08:09:13.504727Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Test Datasets pickles\n",
    "dsrc1 = pickle.loads(pickle.dumps(dsets))\n",
    "test_eq(dsets.train, dsrc1.train)\n",
    "test_eq(dsets.valid, dsrc1.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:24:16.662922Z",
     "start_time": "2021-01-31T09:24:16.652115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [(0, 0),(1, 1),(2, 2),(3, 3),(4, 4)]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets = Datasets(range(5), [_Tfm(),noop], splits=[[1,2],[0,3,4]])\n",
    "dsets\n",
    "test_eq(dsets.train,[(1,1),(2,2)])\n",
    "test_eq(dsets.valid,[(0,0),(6,3),(8,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:13.534900Z",
     "start_time": "2021-01-29T08:09:13.523782Z"
    }
   },
   "outputs": [],
   "source": [
    "start = torch.arange(0,50)\n",
    "tds = Datasets(start, [A()])\n",
    "tdl = TfmdDL(tds, after_item=NegTfm(), bs=4)\n",
    "b = tdl.one_batch()\n",
    "test_eq(tdl.decode_batch(b), ((0,),(1,),(2,),(3,)))\n",
    "test_stdout(tdl.show_batch, \"0\\n1\\n2\\n3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:34:09.822305Z",
     "start_time": "2021-01-31T09:34:09.797784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#8) [(0,),(1,),(2,),(3,),(4,),(5,),(6,),(7,)]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#8) [(0, 0, 0),(1, 1, 1),(2, 2, 2),(3, 3, 3),(4, 4, 4),(5, 5, 5),(6, 6, 6),(7, 7, 7)]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#4) [(0, 0, 0),(3, 3, 3),(4, 4, 4),(6, 6, 6)]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(#4) [(1, 1, 1),(2, 2, 2),(5, 5, 5),(7, 7, 7)]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm(Transform):\n",
    "    split_idx=1\n",
    "    def encodes(self, x): return x*2\n",
    "\n",
    "    \n",
    "dsets = Datasets(range(8), splits=[[1,2,5,7],[0,3,4,6]])\n",
    "dsets\n",
    "dsets = Datasets(range(8),[ None,None, None], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "dsets\n",
    "\n",
    "dsets.valid\n",
    "dsets.train\n",
    "dsets.n_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T09:28:13.086060Z",
     "start_time": "2021-01-31T09:28:11.125052Z"
    }
   },
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm(Transform):\n",
    "    split_idx=1\n",
    "    def encodes(self, x): return x*2\n",
    "\n",
    "dsets = Datasets(range(8), [None], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "dls = dsets.dataloaders(bs=4, after_batch=_Tfm(), shuffle_train=False, device=torch.device('cpu'))\n",
    "test_eq(dls.train, [(tensor([1,2,5, 7]),)])\n",
    "test_eq(dls.valid, [(tensor([0,6,8,12]),)])\n",
    "test_eq(dls.n_inp, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.453961Z",
     "start_time": "2021-01-29T08:09:14.449919Z"
    }
   },
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "dsets = Datasets(items, [[neg_tfm,int2f_tfm]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.472409Z",
     "start_time": "2021-01-29T08:09:14.455360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Datasets.dataloaders\" class=\"doc_header\"><code>Datasets.dataloaders</code><a href=\"__main__.py#L15\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Datasets.dataloaders</code>(**`bs`**=*`64`*, **`val_bs`**=*`None`*, **`shuffle_train`**=*`True`*, **`n`**=*`None`*, **`path`**=*`'.'`*, **`dl_type`**=*`None`*, **`dl_kwargs`**=*`None`*, **`device`**=*`None`*, **`shuffle`**=*`False`*, **`num_workers`**=*`None`*, **`verbose`**=*`False`*, **`do_setup`**=*`True`*, **`pin_memory`**=*`False`*, **`timeout`**=*`0`*, **`batch_size`**=*`None`*, **`drop_last`**=*`False`*, **`indexed`**=*`None`*, **`persistent_workers`**=*`False`*, **`wif`**=*`None`*, **`before_iter`**=*`None`*, **`after_item`**=*`None`*, **`before_batch`**=*`None`*, **`after_batch`**=*`None`*, **`after_iter`**=*`None`*, **`create_batches`**=*`None`*, **`create_item`**=*`None`*, **`create_batch`**=*`None`*, **`retain`**=*`None`*, **`get_idxs`**=*`None`*, **`sample`**=*`None`*, **`shuffle_fn`**=*`None`*, **`do_batch`**=*`None`*)\n",
       "\n",
       "Get a [`DataLoaders`](/data.core#DataLoaders)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_dsrc = Datasets([1,2])\n",
    "(_dsrc.dataloaders, name=\"Datasets.dataloaders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.484608Z",
     "start_time": "2021-01-29T08:09:14.474101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Datasets.decode\" class=\"doc_header\"><code>Datasets.decode</code><a href=\"__main__.py#L20\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Datasets.decode</code>(**`o`**, **`full`**=*`True`*)\n",
       "\n",
       "Compose `decode` of all `tuple_tfms` then all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(Datasets.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.489732Z",
     "start_time": "2021-01-29T08:09:14.486189Z"
    }
   },
   "outputs": [],
   "source": [
    "test_eq(*dsets[0], -1)\n",
    "test_eq(*dsets.decode((-1,)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.501126Z",
     "start_time": "2021-01-29T08:09:14.491256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Datasets.show\" class=\"doc_header\"><code>Datasets.show</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Datasets.show</code>(**`o`**, **`ctx`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item `o` in `ctx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(Datasets.show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.505044Z",
     "start_time": "2021-01-29T08:09:14.502464Z"
    }
   },
   "outputs": [],
   "source": [
    "test_stdout(lambda:dsets.show(dsets[1]), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.513406Z",
     "start_time": "2021-01-29T08:09:14.506601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Datasets.new_empty\" class=\"doc_header\"><code>Datasets.new_empty</code><a href=\"__main__.py#L24\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Datasets.new_empty</code>()\n",
       "\n",
       "Create a new empty version of the `self`, keeping only the transforms"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(Datasets.new_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.518990Z",
     "start_time": "2021-01-29T08:09:14.514604Z"
    }
   },
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "nrm = Norm()\n",
    "dsets = Datasets(items, [[neg_tfm,int2f_tfm], [neg_tfm]])\n",
    "empty = dsets.new_empty()\n",
    "test_eq(empty.items, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.529354Z",
     "start_time": "2021-01-29T08:09:14.520253Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#test it works for dataframes too\n",
    "df = pd.DataFrame({'a':[1,2,3,4,5], 'b':[6,7,8,9,10]})\n",
    "dsets = Datasets(df, [[attrgetter('a')], [attrgetter('b')]])\n",
    "empty = dsets.new_empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add test set for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.538096Z",
     "start_time": "2021-01-29T08:09:14.530591Z"
    }
   },
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm1(Transform):\n",
    "    split_idx=0\n",
    "    def encodes(self, x): return x*3\n",
    "\n",
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm1()]], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "test_eq(dsets.train, [(3,),(6,),(15,),(21,)])\n",
    "test_eq(dsets.valid, [(0,),(6,),(8,),(12,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.547043Z",
     "start_time": "2021-01-29T08:09:14.539404Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_set(dsets, test_items, rm_tfms=None, with_labels=False):\n",
    "    \"Create a test set from `test_items` using validation transforms of `dsets`\"\n",
    "    if isinstance(dsets, Datasets):\n",
    "        tls = dsets.tls if with_labels else dsets.tls[:dsets.n_inp]\n",
    "        test_tls = [tl._new(test_items, split_idx=1) for tl in tls]\n",
    "        if rm_tfms is None: rm_tfms = [tl.infer_idx(get_first(test_items)) for tl in test_tls]\n",
    "        else:               rm_tfms = tuplify(rm_tfms, match=test_tls)\n",
    "        for i,j in enumerate(rm_tfms): test_tls[i].tfms.fs = test_tls[i].tfms.fs[j:]\n",
    "        return Datasets(tls=test_tls)\n",
    "    elif isinstance(dsets, TfmdLists):\n",
    "        test_tl = dsets._new(test_items, split_idx=1)\n",
    "        if rm_tfms is None: rm_tfms = dsets.infer_idx(get_first(test_items))\n",
    "        test_tl.tfms.fs = test_tl.tfms.fs[rm_tfms:]\n",
    "        return test_tl\n",
    "    else: raise Exception(f\"This method requires using the fastai library to assemble your data. Expected a `Datasets` or a `TfmdLists` but got {dsets.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.560645Z",
     "start_time": "2021-01-29T08:09:14.548446Z"
    }
   },
   "outputs": [],
   "source": [
    "class _Tfm1(Transform):\n",
    "    split_idx=0\n",
    "    def encodes(self, x): return x*3\n",
    "\n",
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm1()]], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "test_eq(dsets.train, [(3,),(6,),(15,),(21,)])\n",
    "test_eq(dsets.valid, [(0,),(6,),(8,),(12,)])\n",
    "\n",
    "#Tranform of the validation set are applied\n",
    "tst = test_set(dsets, [1,2,3])\n",
    "test_eq(tst, [(2,),(4,),(6,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.569103Z",
     "start_time": "2021-01-29T08:09:14.562131Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Test with different types\n",
    "tfm = _Tfm1()\n",
    "tfm.split_idx,tfm.order = None,2\n",
    "dsets = Datasets(['dog', 'cat', 'cat', 'dog'], [[_Cat(),tfm]])\n",
    "\n",
    "#With strings\n",
    "test_eq(test_set(dsets, ['dog', 'cat', 'cat']), [(3,), (0,), (0,)])\n",
    "#With ints\n",
    "test_eq(test_set(dsets, [1,2]), [(3,), (6,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.579549Z",
     "start_time": "2021-01-29T08:09:14.570402Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Test with various input lengths\n",
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm1()],[_Tfm(),_Tfm1()],[_Tfm(),_Tfm1()]], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "tst = test_set(dsets, [1,2,3])\n",
    "test_eq(tst, [(2,2),(4,4),(6,6)])\n",
    "\n",
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm1()],[_Tfm(),_Tfm1()],[_Tfm(),_Tfm1()]], splits=[[1,2,5,7],[0,3,4,6]], n_inp=1)\n",
    "tst = test_set(dsets, [1,2,3])\n",
    "test_eq(tst, [(2,),(4,),(6,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.592708Z",
     "start_time": "2021-01-29T08:09:14.580703Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Test with rm_tfms\n",
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm()]], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "tst = test_set(dsets, [1,2,3])\n",
    "test_eq(tst, [(4,),(8,),(12,)])\n",
    "\n",
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm()]], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "tst = test_set(dsets, [1,2,3], rm_tfms=1)\n",
    "test_eq(tst, [(2,),(4,),(6,)])\n",
    "\n",
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm()], [_Tfm(),_Tfm()]], splits=[[1,2,5,7],[0,3,4,6]], n_inp=2)\n",
    "tst = test_set(dsets, [1,2,3], rm_tfms=(1,0))\n",
    "test_eq(tst, [(2,4),(4,8),(6,12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.599077Z",
     "start_time": "2021-01-29T08:09:14.593757Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@patch\n",
    "@delegates(TfmdDL.__init__)\n",
    "def test_dl(self:DataLoaders, test_items, rm_type_tfms=None, with_labels=False, **kwargs):\n",
    "    \"Create a test dataloader from `test_items` using validation transforms of `dls`\"\n",
    "    test_ds = test_set(self.valid_ds, test_items, rm_tfms=rm_type_tfms, with_labels=with_labels\n",
    "                      ) if isinstance(self.valid_ds, (Datasets, TfmdLists)) else test_items\n",
    "    return self.valid.new(test_ds, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:14.606587Z",
     "start_time": "2021-01-29T08:09:14.600356Z"
    }
   },
   "outputs": [],
   "source": [
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm1()]], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "dls = dsets.dataloaders(bs=4, device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T08:09:15.476449Z",
     "start_time": "2021-01-29T08:09:14.607989Z"
    }
   },
   "outputs": [],
   "source": [
    "dsets = Datasets(range(8), [[_Tfm(),_Tfm1()]], splits=[[1,2,5,7],[0,3,4,6]])\n",
    "dls = dsets.dataloaders(bs=4, device=torch.device('cpu'))\n",
    "tst_dl = dls.test_dl([2,3,4,5])\n",
    "test_eq(tst_dl._n_inp, 1)\n",
    "test_eq(list(tst_dl), [(tensor([ 4,  6,  8, 10]),)])\n",
    "#Test you can change transforms\n",
    "tst_dl = dls.test_dl([2,3,4,5], after_item=add1)\n",
    "test_eq(list(tst_dl), [(tensor([ 5,  7,  9, 11]),)])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:new] *",
   "language": "python",
   "name": "conda-env-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
