{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- sticky_rank: 3\n",
    "- author: Bowen\n",
    "- categories: [pytorch, fastai]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:16.060614Z",
     "start_time": "2020-09-16T05:05:15.067895Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Softmax\n",
    "from fastcore.foundation import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.dispatch import typedispatch\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import inspect\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.loli.net/2020/09/15/t9KXn8cu51wDsiG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:16.067874Z",
     "start_time": "2020-09-16T05:05:16.062736Z"
    }
   },
   "outputs": [],
   "source": [
    "def INF(B,H,W):\n",
    "     return -torch.diag(torch.tensor(float(\"inf\")).cuda().repeat(H),0).unsqueeze(0).repeat(B*W,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why use contiguous method in pytorch? https://zhuanlan.zhihu.com/p/64551412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:16.095081Z",
     "start_time": "2020-09-16T05:05:16.070513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   1,   2,   3,   4],\n",
       "         [  5,   6,   7,   8,   9],\n",
       "         [ 10,  11,  12,  13,  14],\n",
       "         [ 15,  16,  17,  18,  19],\n",
       "         [ 20,  21,  22,  23,  24]],\n",
       "\n",
       "        [[ 25,  26,  27,  28,  29],\n",
       "         [ 30,  31,  32,  33,  34],\n",
       "         [ 35,  36,  37,  38,  39],\n",
       "         [ 40,  41,  42,  43,  44],\n",
       "         [ 45,  46,  47,  48,  49]],\n",
       "\n",
       "        [[ 50,  51,  52,  53,  54],\n",
       "         [ 55,  56,  57,  58,  59],\n",
       "         [ 60,  61,  62,  63,  64],\n",
       "         [ 65,  66,  67,  68,  69],\n",
       "         [ 70,  71,  72,  73,  74]],\n",
       "\n",
       "        [[ 75,  76,  77,  78,  79],\n",
       "         [ 80,  81,  82,  83,  84],\n",
       "         [ 85,  86,  87,  88,  89],\n",
       "         [ 90,  91,  92,  93,  94],\n",
       "         [ 95,  96,  97,  98,  99]],\n",
       "\n",
       "        [[100, 101, 102, 103, 104],\n",
       "         [105, 106, 107, 108, 109],\n",
       "         [110, 111, 112, 113, 114],\n",
       "         [115, 116, 117, 118, 119],\n",
       "         [120, 121, 122, 123, 124]],\n",
       "\n",
       "        [[125, 126, 127, 128, 129],\n",
       "         [130, 131, 132, 133, 134],\n",
       "         [135, 136, 137, 138, 139],\n",
       "         [140, 141, 142, 143, 144],\n",
       "         [145, 146, 147, 148, 149]],\n",
       "\n",
       "        [[150, 151, 152, 153, 154],\n",
       "         [155, 156, 157, 158, 159],\n",
       "         [160, 161, 162, 163, 164],\n",
       "         [165, 166, 167, 168, 169],\n",
       "         [170, 171, 172, 173, 174]],\n",
       "\n",
       "        [[175, 176, 177, 178, 179],\n",
       "         [180, 181, 182, 183, 184],\n",
       "         [185, 186, 187, 188, 189],\n",
       "         [190, 191, 192, 193, 194],\n",
       "         [195, 196, 197, 198, 199]],\n",
       "\n",
       "        [[200, 201, 202, 203, 204],\n",
       "         [205, 206, 207, 208, 209],\n",
       "         [210, 211, 212, 213, 214],\n",
       "         [215, 216, 217, 218, 219],\n",
       "         [220, 221, 222, 223, 224]],\n",
       "\n",
       "        [[225, 226, 227, 228, 229],\n",
       "         [230, 231, 232, 233, 234],\n",
       "         [235, 236, 237, 238, 239],\n",
       "         [240, 241, 242, 243, 244],\n",
       "         [245, 246, 247, 248, 249]],\n",
       "\n",
       "        [[250, 251, 252, 253, 254],\n",
       "         [255, 256, 257, 258, 259],\n",
       "         [260, 261, 262, 263, 264],\n",
       "         [265, 266, 267, 268, 269],\n",
       "         [270, 271, 272, 273, 274]],\n",
       "\n",
       "        [[275, 276, 277, 278, 279],\n",
       "         [280, 281, 282, 283, 284],\n",
       "         [285, 286, 287, 288, 289],\n",
       "         [290, 291, 292, 293, 294],\n",
       "         [295, 296, 297, 298, 299]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(25, 5, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = torch.arange(300).reshape(12,5,5)\n",
    "aa\n",
    "aa.stride()\n",
    "aa.stride(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:16.101876Z",
     "start_time": "2020-09-16T05:05:16.096862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.tensor(1).repeat(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:18.057238Z",
     "start_time": "2020-09-16T05:05:16.103019Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]],\n",
       "\n",
       "        [[-inf, -0., -0., -0., -0.],\n",
       "         [-0., -inf, -0., -0., -0.],\n",
       "         [-0., -0., -inf, -0., -0.],\n",
       "         [-0., -0., -0., -inf, -0.],\n",
       "         [-0., -0., -0., -0., -inf]]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 5, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = INF(2,5,6)\n",
    "bb\n",
    "\n",
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:18.083180Z",
     "start_time": "2020-09-16T05:05:18.058417Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-inf,   1.,   2.,   3.,   4.],\n",
       "          [-inf,  26.,  27.,  28.,  29.],\n",
       "          [-inf,  51.,  52.,  53.,  54.],\n",
       "          [-inf,  76.,  77.,  78.,  79.],\n",
       "          [-inf, 101., 102., 103., 104.],\n",
       "          [-inf, 126., 127., 128., 129.]],\n",
       "\n",
       "         [[  5., -inf,   7.,   8.,   9.],\n",
       "          [ 30., -inf,  32.,  33.,  34.],\n",
       "          [ 55., -inf,  57.,  58.,  59.],\n",
       "          [ 80., -inf,  82.,  83.,  84.],\n",
       "          [105., -inf, 107., 108., 109.],\n",
       "          [130., -inf, 132., 133., 134.]],\n",
       "\n",
       "         [[ 10.,  11., -inf,  13.,  14.],\n",
       "          [ 35.,  36., -inf,  38.,  39.],\n",
       "          [ 60.,  61., -inf,  63.,  64.],\n",
       "          [ 85.,  86., -inf,  88.,  89.],\n",
       "          [110., 111., -inf, 113., 114.],\n",
       "          [135., 136., -inf, 138., 139.]],\n",
       "\n",
       "         [[ 15.,  16.,  17., -inf,  19.],\n",
       "          [ 40.,  41.,  42., -inf,  44.],\n",
       "          [ 65.,  66.,  67., -inf,  69.],\n",
       "          [ 90.,  91.,  92., -inf,  94.],\n",
       "          [115., 116., 117., -inf, 119.],\n",
       "          [140., 141., 142., -inf, 144.]],\n",
       "\n",
       "         [[ 20.,  21.,  22.,  23., -inf],\n",
       "          [ 45.,  46.,  47.,  48., -inf],\n",
       "          [ 70.,  71.,  72.,  73., -inf],\n",
       "          [ 95.,  96.,  97.,  98., -inf],\n",
       "          [120., 121., 122., 123., -inf],\n",
       "          [145., 146., 147., 148., -inf]]],\n",
       "\n",
       "\n",
       "        [[[-inf, 151., 152., 153., 154.],\n",
       "          [-inf, 176., 177., 178., 179.],\n",
       "          [-inf, 201., 202., 203., 204.],\n",
       "          [-inf, 226., 227., 228., 229.],\n",
       "          [-inf, 251., 252., 253., 254.],\n",
       "          [-inf, 276., 277., 278., 279.]],\n",
       "\n",
       "         [[155., -inf, 157., 158., 159.],\n",
       "          [180., -inf, 182., 183., 184.],\n",
       "          [205., -inf, 207., 208., 209.],\n",
       "          [230., -inf, 232., 233., 234.],\n",
       "          [255., -inf, 257., 258., 259.],\n",
       "          [280., -inf, 282., 283., 284.]],\n",
       "\n",
       "         [[160., 161., -inf, 163., 164.],\n",
       "          [185., 186., -inf, 188., 189.],\n",
       "          [210., 211., -inf, 213., 214.],\n",
       "          [235., 236., -inf, 238., 239.],\n",
       "          [260., 261., -inf, 263., 264.],\n",
       "          [285., 286., -inf, 288., 289.]],\n",
       "\n",
       "         [[165., 166., 167., -inf, 169.],\n",
       "          [190., 191., 192., -inf, 194.],\n",
       "          [215., 216., 217., -inf, 219.],\n",
       "          [240., 241., 242., -inf, 244.],\n",
       "          [265., 266., 267., -inf, 269.],\n",
       "          [290., 291., 292., -inf, 294.]],\n",
       "\n",
       "         [[170., 171., 172., 173., -inf],\n",
       "          [195., 196., 197., 198., -inf],\n",
       "          [220., 221., 222., 223., -inf],\n",
       "          [245., 246., 247., 248., -inf],\n",
       "          [270., 271., 272., 273., -inf],\n",
       "          [295., 296., 297., 298., -inf]]]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = (aa.cuda()+bb).cuda().view(2,6,5,5).permute(0,2,1,3);cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:18.101059Z",
     "start_time": "2020-09-16T05:05:18.084483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9046bb1310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5256e+00, -7.5023e-01, -6.5398e-01, -1.6095e+00, -1.0017e-01,\n",
       "           -6.0919e-01],\n",
       "          [-9.7977e-01, -1.6091e+00, -7.1214e-01,  3.0372e-01, -7.7731e-01,\n",
       "           -2.5146e-01],\n",
       "          [-2.2227e-01,  1.6871e+00,  2.2843e-01,  4.6764e-01, -6.9697e-01,\n",
       "           -1.1608e+00],\n",
       "          [ 6.9954e-01,  1.9908e-01,  8.6569e-01,  2.4440e-01, -6.6291e-01,\n",
       "            8.0731e-01],\n",
       "          [ 1.1017e+00, -1.7594e-01, -2.2456e+00, -1.4465e+00,  6.1155e-02,\n",
       "           -6.1774e-01],\n",
       "          [-7.9807e-01, -1.3162e-01,  1.8793e+00, -7.2132e-02,  1.5777e-01,\n",
       "           -7.7345e-01]],\n",
       "\n",
       "         [[ 1.9906e-01,  4.5703e-02,  1.5296e-01, -4.7568e-01, -1.1102e-01,\n",
       "            2.9274e-01],\n",
       "          [-1.5785e-01, -2.8787e-02,  2.3571e+00, -1.0373e+00,  1.5748e+00,\n",
       "           -6.2985e-01],\n",
       "          [-9.2739e-01,  5.4514e-01,  6.6280e-02, -4.3704e-01,  7.6260e-01,\n",
       "            4.4151e-01],\n",
       "          [ 1.1651e+00,  2.0154e+00,  1.3741e-01,  9.3864e-01, -1.8600e-01,\n",
       "           -6.4464e-01],\n",
       "          [ 1.5392e+00, -8.6959e-01, -3.3312e+00, -7.4787e-01, -2.5502e-02,\n",
       "           -1.0233e+00],\n",
       "          [-5.9619e-01, -1.0055e+00, -2.1061e-01, -7.5475e-03,  1.6734e+00,\n",
       "            1.0343e-02]],\n",
       "\n",
       "         [[-7.0396e-01, -1.8527e-01, -9.9624e-01, -8.3126e-01, -4.6102e-01,\n",
       "           -5.6008e-01],\n",
       "          [ 3.9558e-01, -9.8228e-01, -5.0649e-01,  9.9775e-02, -6.5397e-01,\n",
       "            7.3169e-01],\n",
       "          [-1.4344e+00, -5.0081e-01,  1.7163e-01, -1.5999e-01,  2.5463e-01,\n",
       "           -5.0196e-01],\n",
       "          [-1.0412e+00,  7.3227e-01, -1.0483e+00, -4.7088e-01,  2.9114e-01,\n",
       "            1.9907e+00],\n",
       "          [ 6.6145e-01,  1.1899e+00,  8.1653e-01, -9.1352e-01,  1.3851e+00,\n",
       "           -8.1385e-01],\n",
       "          [-9.2758e-01,  1.1120e+00,  1.3352e+00,  6.0427e-01, -1.0344e-01,\n",
       "           -1.5122e-01]],\n",
       "\n",
       "         [[-2.1021e+00, -6.2002e-01, -1.4782e+00, -1.1334e+00,  8.7380e-01,\n",
       "           -5.6026e-01],\n",
       "          [ 1.2858e+00,  8.1682e-01,  2.0530e-01,  3.0511e-01,  5.3569e-01,\n",
       "           -4.3119e-01],\n",
       "          [ 2.5581e+00, -2.3336e-01, -1.3472e-02,  1.8606e+00, -1.9804e+00,\n",
       "            1.7986e+00],\n",
       "          [ 1.0181e-01,  3.4001e-01,  7.1236e-01, -1.7765e+00,  3.5386e-01,\n",
       "            1.1996e+00],\n",
       "          [-3.0300e-01, -1.7618e+00,  6.3484e-01, -8.0436e-01, -1.6111e+00,\n",
       "           -1.8716e+00],\n",
       "          [ 5.4308e-01,  6.6068e-01,  2.2952e+00,  6.7491e-01,  1.7133e+00,\n",
       "           -1.7943e+00]],\n",
       "\n",
       "         [[-1.3633e+00, -9.8322e-01,  1.5113e+00,  6.4187e-01,  4.7296e-01,\n",
       "           -4.2859e-01],\n",
       "          [ 5.5137e-01, -1.5474e+00,  5.1811e-01,  1.0654e-01,  2.6924e-01,\n",
       "            1.3248e+00],\n",
       "          [ 1.7460e+00,  1.8550e+00, -7.0637e-01,  2.5571e+00,  4.1753e-01,\n",
       "           -2.1272e-01],\n",
       "          [-8.3996e-01, -4.2002e-01, -6.2404e-01, -9.7730e-01,  8.7484e-01,\n",
       "            9.8728e-01],\n",
       "          [ 3.0958e-01,  1.5207e+00,  1.2052e+00, -1.8156e+00, -4.0346e-01,\n",
       "           -9.5915e-01],\n",
       "          [-5.2077e-03, -7.8863e-02,  8.4365e-01,  1.1657e+00,  5.2693e-01,\n",
       "            1.6193e+00]]],\n",
       "\n",
       "\n",
       "        [[[-9.6398e-01,  1.4152e-01, -1.6366e-01, -3.5822e-01,  1.7223e+00,\n",
       "           -3.0358e-01],\n",
       "          [ 2.3887e-01,  1.3440e+00,  1.0323e-01,  1.1004e+00, -3.4168e-01,\n",
       "            9.4734e-01],\n",
       "          [-5.6852e-01,  8.3760e-01,  1.7837e+00, -1.9542e-01,  5.1492e-01,\n",
       "           -1.8475e+00],\n",
       "          [-2.9167e+00, -5.6733e-01, -5.4128e-01,  8.9517e-01, -8.8251e-01,\n",
       "            5.3181e-01],\n",
       "          [-1.5458e+00, -1.7330e-01,  7.2825e-01,  5.7061e-02,  9.0552e-01,\n",
       "            1.0463e+00],\n",
       "          [-5.2060e-01,  1.3548e+00,  2.3519e-01,  1.9142e+00,  1.8364e+00,\n",
       "            1.3245e+00]],\n",
       "\n",
       "         [[-9.6901e-01,  1.2516e+00,  1.2103e+00, -5.2792e-01,  2.1857e-01,\n",
       "           -5.7431e-01],\n",
       "          [ 1.4571e+00,  1.7710e+00,  1.6499e+00, -4.3200e-01, -2.7103e-01,\n",
       "           -1.4392e+00],\n",
       "          [ 1.2470e+00,  1.2739e+00,  3.9095e-01,  3.8721e-01, -7.9829e-02,\n",
       "            3.4172e-01],\n",
       "          [ 9.4883e-01, -1.3839e+00,  1.7241e+00, -2.3648e+00, -9.2949e-01,\n",
       "            2.9363e-01],\n",
       "          [ 2.1513e-01,  9.3846e-01,  1.4657e+00, -5.5647e-01, -7.4484e-01,\n",
       "           -2.0216e-01],\n",
       "          [-2.2967e-01,  1.3313e-03,  3.7528e-01, -5.8107e-01, -5.7231e-01,\n",
       "            1.0097e+00]],\n",
       "\n",
       "         [[-1.0565e-01, -1.1797e+00, -9.0780e-02,  5.6311e-01, -1.2560e+00,\n",
       "            8.9556e-01],\n",
       "          [ 1.6748e-01,  7.5142e-01,  2.4142e+00,  1.0206e+00, -4.4048e-01,\n",
       "           -1.7342e+00],\n",
       "          [-1.2362e+00,  1.5786e+00, -1.1161e+00,  7.6777e-01, -5.8821e-01,\n",
       "            2.1189e+00],\n",
       "          [-5.4219e-01, -2.4593e+00, -1.1108e+00, -1.1187e+00,  7.5800e-01,\n",
       "           -4.9566e-01],\n",
       "          [-1.9700e-01, -3.3396e-02,  7.1929e-01,  1.0644e+00,  8.3403e-01,\n",
       "           -1.9162e+00],\n",
       "          [-3.4203e-01, -6.6049e-01,  3.1509e-01,  1.1423e+00,  3.0551e-01,\n",
       "           -5.7888e-01]],\n",
       "\n",
       "         [[-2.3828e-01, -1.3542e+00,  2.6869e-01,  1.1456e-01, -1.5563e+00,\n",
       "           -1.0757e+00],\n",
       "          [-8.7519e-01, -4.7282e-01,  9.9124e-01, -5.8622e-02,  1.1788e+00,\n",
       "            6.2218e-01],\n",
       "          [ 7.8785e-01,  1.3686e+00, -8.5069e-01,  5.1261e-01,  1.0476e+00,\n",
       "           -3.1758e-01],\n",
       "          [ 1.3949e-01,  2.3403e+00, -6.1161e-01,  8.1603e-01,  2.4772e-01,\n",
       "           -3.8673e-01],\n",
       "          [ 1.9948e-01,  7.9927e-01, -2.6190e-01,  1.5133e-01,  1.1982e+00,\n",
       "           -2.2833e+00],\n",
       "          [-1.0130e+00, -8.8789e-01,  6.5222e-01, -8.7262e-01,  3.5254e-02,\n",
       "           -3.3653e-01]],\n",
       "\n",
       "         [[ 1.4023e+00,  4.8412e-01, -7.0305e-01, -8.2677e-01,  7.7440e-01,\n",
       "            6.9199e-01],\n",
       "          [-1.0185e+00, -8.0337e-01, -7.0711e-01,  7.5212e-01, -1.9208e-02,\n",
       "            1.1033e+00],\n",
       "          [-6.0679e-01, -5.2522e-01, -5.6619e-01,  6.6040e-04,  7.2246e-01,\n",
       "            1.5264e-01],\n",
       "          [ 1.4496e-01, -2.3442e+00, -4.3273e-01, -1.1498e-01,  1.7964e+00,\n",
       "           -4.7741e-01],\n",
       "          [-1.5521e+00, -6.4898e-01, -7.7376e-02, -6.0421e-01, -5.2757e-01,\n",
       "            8.4868e-02],\n",
       "          [ 1.9454e-01, -9.4179e-01, -1.8792e-01,  1.0325e+00, -2.4865e-01,\n",
       "           -4.7209e-01]]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "dd = torch.randn(2,5,6,6).cuda()\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:17:28.947683Z",
     "start_time": "2020-09-16T05:17:28.942269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 6, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:18.123210Z",
     "start_time": "2020-09-16T05:05:18.102584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 6, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[       -inf,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
       "           -1.5256e+00, -7.5023e-01, -6.5398e-01, -1.6095e+00, -1.0017e-01,\n",
       "           -6.0919e-01],\n",
       "          [       -inf,  2.6000e+01,  2.7000e+01,  2.8000e+01,  2.9000e+01,\n",
       "           -9.7977e-01, -1.6091e+00, -7.1214e-01,  3.0372e-01, -7.7731e-01,\n",
       "           -2.5146e-01],\n",
       "          [       -inf,  5.1000e+01,  5.2000e+01,  5.3000e+01,  5.4000e+01,\n",
       "           -2.2227e-01,  1.6871e+00,  2.2843e-01,  4.6764e-01, -6.9697e-01,\n",
       "           -1.1608e+00],\n",
       "          [       -inf,  7.6000e+01,  7.7000e+01,  7.8000e+01,  7.9000e+01,\n",
       "            6.9954e-01,  1.9908e-01,  8.6569e-01,  2.4440e-01, -6.6291e-01,\n",
       "            8.0731e-01],\n",
       "          [       -inf,  1.0100e+02,  1.0200e+02,  1.0300e+02,  1.0400e+02,\n",
       "            1.1017e+00, -1.7594e-01, -2.2456e+00, -1.4465e+00,  6.1155e-02,\n",
       "           -6.1774e-01],\n",
       "          [       -inf,  1.2600e+02,  1.2700e+02,  1.2800e+02,  1.2900e+02,\n",
       "           -7.9807e-01, -1.3162e-01,  1.8793e+00, -7.2132e-02,  1.5777e-01,\n",
       "           -7.7345e-01]],\n",
       "\n",
       "         [[ 5.0000e+00,        -inf,  7.0000e+00,  8.0000e+00,  9.0000e+00,\n",
       "            1.9906e-01,  4.5703e-02,  1.5296e-01, -4.7568e-01, -1.1102e-01,\n",
       "            2.9274e-01],\n",
       "          [ 3.0000e+01,        -inf,  3.2000e+01,  3.3000e+01,  3.4000e+01,\n",
       "           -1.5785e-01, -2.8787e-02,  2.3571e+00, -1.0373e+00,  1.5748e+00,\n",
       "           -6.2985e-01],\n",
       "          [ 5.5000e+01,        -inf,  5.7000e+01,  5.8000e+01,  5.9000e+01,\n",
       "           -9.2739e-01,  5.4514e-01,  6.6280e-02, -4.3704e-01,  7.6260e-01,\n",
       "            4.4151e-01],\n",
       "          [ 8.0000e+01,        -inf,  8.2000e+01,  8.3000e+01,  8.4000e+01,\n",
       "            1.1651e+00,  2.0154e+00,  1.3741e-01,  9.3864e-01, -1.8600e-01,\n",
       "           -6.4464e-01],\n",
       "          [ 1.0500e+02,        -inf,  1.0700e+02,  1.0800e+02,  1.0900e+02,\n",
       "            1.5392e+00, -8.6959e-01, -3.3312e+00, -7.4787e-01, -2.5502e-02,\n",
       "           -1.0233e+00],\n",
       "          [ 1.3000e+02,        -inf,  1.3200e+02,  1.3300e+02,  1.3400e+02,\n",
       "           -5.9619e-01, -1.0055e+00, -2.1061e-01, -7.5475e-03,  1.6734e+00,\n",
       "            1.0343e-02]],\n",
       "\n",
       "         [[ 1.0000e+01,  1.1000e+01,        -inf,  1.3000e+01,  1.4000e+01,\n",
       "           -7.0396e-01, -1.8527e-01, -9.9624e-01, -8.3126e-01, -4.6102e-01,\n",
       "           -5.6008e-01],\n",
       "          [ 3.5000e+01,  3.6000e+01,        -inf,  3.8000e+01,  3.9000e+01,\n",
       "            3.9558e-01, -9.8228e-01, -5.0649e-01,  9.9775e-02, -6.5397e-01,\n",
       "            7.3169e-01],\n",
       "          [ 6.0000e+01,  6.1000e+01,        -inf,  6.3000e+01,  6.4000e+01,\n",
       "           -1.4344e+00, -5.0081e-01,  1.7163e-01, -1.5999e-01,  2.5463e-01,\n",
       "           -5.0196e-01],\n",
       "          [ 8.5000e+01,  8.6000e+01,        -inf,  8.8000e+01,  8.9000e+01,\n",
       "           -1.0412e+00,  7.3227e-01, -1.0483e+00, -4.7088e-01,  2.9114e-01,\n",
       "            1.9907e+00],\n",
       "          [ 1.1000e+02,  1.1100e+02,        -inf,  1.1300e+02,  1.1400e+02,\n",
       "            6.6145e-01,  1.1899e+00,  8.1653e-01, -9.1352e-01,  1.3851e+00,\n",
       "           -8.1385e-01],\n",
       "          [ 1.3500e+02,  1.3600e+02,        -inf,  1.3800e+02,  1.3900e+02,\n",
       "           -9.2758e-01,  1.1120e+00,  1.3352e+00,  6.0427e-01, -1.0344e-01,\n",
       "           -1.5122e-01]],\n",
       "\n",
       "         [[ 1.5000e+01,  1.6000e+01,  1.7000e+01,        -inf,  1.9000e+01,\n",
       "           -2.1021e+00, -6.2002e-01, -1.4782e+00, -1.1334e+00,  8.7380e-01,\n",
       "           -5.6026e-01],\n",
       "          [ 4.0000e+01,  4.1000e+01,  4.2000e+01,        -inf,  4.4000e+01,\n",
       "            1.2858e+00,  8.1682e-01,  2.0530e-01,  3.0511e-01,  5.3569e-01,\n",
       "           -4.3119e-01],\n",
       "          [ 6.5000e+01,  6.6000e+01,  6.7000e+01,        -inf,  6.9000e+01,\n",
       "            2.5581e+00, -2.3336e-01, -1.3472e-02,  1.8606e+00, -1.9804e+00,\n",
       "            1.7986e+00],\n",
       "          [ 9.0000e+01,  9.1000e+01,  9.2000e+01,        -inf,  9.4000e+01,\n",
       "            1.0181e-01,  3.4001e-01,  7.1236e-01, -1.7765e+00,  3.5386e-01,\n",
       "            1.1996e+00],\n",
       "          [ 1.1500e+02,  1.1600e+02,  1.1700e+02,        -inf,  1.1900e+02,\n",
       "           -3.0300e-01, -1.7618e+00,  6.3484e-01, -8.0436e-01, -1.6111e+00,\n",
       "           -1.8716e+00],\n",
       "          [ 1.4000e+02,  1.4100e+02,  1.4200e+02,        -inf,  1.4400e+02,\n",
       "            5.4308e-01,  6.6068e-01,  2.2952e+00,  6.7491e-01,  1.7133e+00,\n",
       "           -1.7943e+00]],\n",
       "\n",
       "         [[ 2.0000e+01,  2.1000e+01,  2.2000e+01,  2.3000e+01,        -inf,\n",
       "           -1.3633e+00, -9.8322e-01,  1.5113e+00,  6.4187e-01,  4.7296e-01,\n",
       "           -4.2859e-01],\n",
       "          [ 4.5000e+01,  4.6000e+01,  4.7000e+01,  4.8000e+01,        -inf,\n",
       "            5.5137e-01, -1.5474e+00,  5.1811e-01,  1.0654e-01,  2.6924e-01,\n",
       "            1.3248e+00],\n",
       "          [ 7.0000e+01,  7.1000e+01,  7.2000e+01,  7.3000e+01,        -inf,\n",
       "            1.7460e+00,  1.8550e+00, -7.0637e-01,  2.5571e+00,  4.1753e-01,\n",
       "           -2.1272e-01],\n",
       "          [ 9.5000e+01,  9.6000e+01,  9.7000e+01,  9.8000e+01,        -inf,\n",
       "           -8.3996e-01, -4.2002e-01, -6.2404e-01, -9.7730e-01,  8.7484e-01,\n",
       "            9.8728e-01],\n",
       "          [ 1.2000e+02,  1.2100e+02,  1.2200e+02,  1.2300e+02,        -inf,\n",
       "            3.0958e-01,  1.5207e+00,  1.2052e+00, -1.8156e+00, -4.0346e-01,\n",
       "           -9.5915e-01],\n",
       "          [ 1.4500e+02,  1.4600e+02,  1.4700e+02,  1.4800e+02,        -inf,\n",
       "           -5.2077e-03, -7.8863e-02,  8.4365e-01,  1.1657e+00,  5.2693e-01,\n",
       "            1.6193e+00]]],\n",
       "\n",
       "\n",
       "        [[[       -inf,  1.5100e+02,  1.5200e+02,  1.5300e+02,  1.5400e+02,\n",
       "           -9.6398e-01,  1.4152e-01, -1.6366e-01, -3.5822e-01,  1.7223e+00,\n",
       "           -3.0358e-01],\n",
       "          [       -inf,  1.7600e+02,  1.7700e+02,  1.7800e+02,  1.7900e+02,\n",
       "            2.3887e-01,  1.3440e+00,  1.0323e-01,  1.1004e+00, -3.4168e-01,\n",
       "            9.4734e-01],\n",
       "          [       -inf,  2.0100e+02,  2.0200e+02,  2.0300e+02,  2.0400e+02,\n",
       "           -5.6852e-01,  8.3760e-01,  1.7837e+00, -1.9542e-01,  5.1492e-01,\n",
       "           -1.8475e+00],\n",
       "          [       -inf,  2.2600e+02,  2.2700e+02,  2.2800e+02,  2.2900e+02,\n",
       "           -2.9167e+00, -5.6733e-01, -5.4128e-01,  8.9517e-01, -8.8251e-01,\n",
       "            5.3181e-01],\n",
       "          [       -inf,  2.5100e+02,  2.5200e+02,  2.5300e+02,  2.5400e+02,\n",
       "           -1.5458e+00, -1.7330e-01,  7.2825e-01,  5.7061e-02,  9.0552e-01,\n",
       "            1.0463e+00],\n",
       "          [       -inf,  2.7600e+02,  2.7700e+02,  2.7800e+02,  2.7900e+02,\n",
       "           -5.2060e-01,  1.3548e+00,  2.3519e-01,  1.9142e+00,  1.8364e+00,\n",
       "            1.3245e+00]],\n",
       "\n",
       "         [[ 1.5500e+02,        -inf,  1.5700e+02,  1.5800e+02,  1.5900e+02,\n",
       "           -9.6901e-01,  1.2516e+00,  1.2103e+00, -5.2792e-01,  2.1857e-01,\n",
       "           -5.7431e-01],\n",
       "          [ 1.8000e+02,        -inf,  1.8200e+02,  1.8300e+02,  1.8400e+02,\n",
       "            1.4571e+00,  1.7710e+00,  1.6499e+00, -4.3200e-01, -2.7103e-01,\n",
       "           -1.4392e+00],\n",
       "          [ 2.0500e+02,        -inf,  2.0700e+02,  2.0800e+02,  2.0900e+02,\n",
       "            1.2470e+00,  1.2739e+00,  3.9095e-01,  3.8721e-01, -7.9829e-02,\n",
       "            3.4172e-01],\n",
       "          [ 2.3000e+02,        -inf,  2.3200e+02,  2.3300e+02,  2.3400e+02,\n",
       "            9.4883e-01, -1.3839e+00,  1.7241e+00, -2.3648e+00, -9.2949e-01,\n",
       "            2.9363e-01],\n",
       "          [ 2.5500e+02,        -inf,  2.5700e+02,  2.5800e+02,  2.5900e+02,\n",
       "            2.1513e-01,  9.3846e-01,  1.4657e+00, -5.5647e-01, -7.4484e-01,\n",
       "           -2.0216e-01],\n",
       "          [ 2.8000e+02,        -inf,  2.8200e+02,  2.8300e+02,  2.8400e+02,\n",
       "           -2.2967e-01,  1.3313e-03,  3.7528e-01, -5.8107e-01, -5.7231e-01,\n",
       "            1.0097e+00]],\n",
       "\n",
       "         [[ 1.6000e+02,  1.6100e+02,        -inf,  1.6300e+02,  1.6400e+02,\n",
       "           -1.0565e-01, -1.1797e+00, -9.0780e-02,  5.6311e-01, -1.2560e+00,\n",
       "            8.9556e-01],\n",
       "          [ 1.8500e+02,  1.8600e+02,        -inf,  1.8800e+02,  1.8900e+02,\n",
       "            1.6748e-01,  7.5142e-01,  2.4142e+00,  1.0206e+00, -4.4048e-01,\n",
       "           -1.7342e+00],\n",
       "          [ 2.1000e+02,  2.1100e+02,        -inf,  2.1300e+02,  2.1400e+02,\n",
       "           -1.2362e+00,  1.5786e+00, -1.1161e+00,  7.6777e-01, -5.8821e-01,\n",
       "            2.1189e+00],\n",
       "          [ 2.3500e+02,  2.3600e+02,        -inf,  2.3800e+02,  2.3900e+02,\n",
       "           -5.4219e-01, -2.4593e+00, -1.1108e+00, -1.1187e+00,  7.5800e-01,\n",
       "           -4.9566e-01],\n",
       "          [ 2.6000e+02,  2.6100e+02,        -inf,  2.6300e+02,  2.6400e+02,\n",
       "           -1.9700e-01, -3.3396e-02,  7.1929e-01,  1.0644e+00,  8.3403e-01,\n",
       "           -1.9162e+00],\n",
       "          [ 2.8500e+02,  2.8600e+02,        -inf,  2.8800e+02,  2.8900e+02,\n",
       "           -3.4203e-01, -6.6049e-01,  3.1509e-01,  1.1423e+00,  3.0551e-01,\n",
       "           -5.7888e-01]],\n",
       "\n",
       "         [[ 1.6500e+02,  1.6600e+02,  1.6700e+02,        -inf,  1.6900e+02,\n",
       "           -2.3828e-01, -1.3542e+00,  2.6869e-01,  1.1456e-01, -1.5563e+00,\n",
       "           -1.0757e+00],\n",
       "          [ 1.9000e+02,  1.9100e+02,  1.9200e+02,        -inf,  1.9400e+02,\n",
       "           -8.7519e-01, -4.7282e-01,  9.9124e-01, -5.8622e-02,  1.1788e+00,\n",
       "            6.2218e-01],\n",
       "          [ 2.1500e+02,  2.1600e+02,  2.1700e+02,        -inf,  2.1900e+02,\n",
       "            7.8785e-01,  1.3686e+00, -8.5069e-01,  5.1261e-01,  1.0476e+00,\n",
       "           -3.1758e-01],\n",
       "          [ 2.4000e+02,  2.4100e+02,  2.4200e+02,        -inf,  2.4400e+02,\n",
       "            1.3949e-01,  2.3403e+00, -6.1161e-01,  8.1603e-01,  2.4772e-01,\n",
       "           -3.8673e-01],\n",
       "          [ 2.6500e+02,  2.6600e+02,  2.6700e+02,        -inf,  2.6900e+02,\n",
       "            1.9948e-01,  7.9927e-01, -2.6190e-01,  1.5133e-01,  1.1982e+00,\n",
       "           -2.2833e+00],\n",
       "          [ 2.9000e+02,  2.9100e+02,  2.9200e+02,        -inf,  2.9400e+02,\n",
       "           -1.0130e+00, -8.8789e-01,  6.5222e-01, -8.7262e-01,  3.5254e-02,\n",
       "           -3.3653e-01]],\n",
       "\n",
       "         [[ 1.7000e+02,  1.7100e+02,  1.7200e+02,  1.7300e+02,        -inf,\n",
       "            1.4023e+00,  4.8412e-01, -7.0305e-01, -8.2677e-01,  7.7440e-01,\n",
       "            6.9199e-01],\n",
       "          [ 1.9500e+02,  1.9600e+02,  1.9700e+02,  1.9800e+02,        -inf,\n",
       "           -1.0185e+00, -8.0337e-01, -7.0711e-01,  7.5212e-01, -1.9208e-02,\n",
       "            1.1033e+00],\n",
       "          [ 2.2000e+02,  2.2100e+02,  2.2200e+02,  2.2300e+02,        -inf,\n",
       "           -6.0679e-01, -5.2522e-01, -5.6619e-01,  6.6040e-04,  7.2246e-01,\n",
       "            1.5264e-01],\n",
       "          [ 2.4500e+02,  2.4600e+02,  2.4700e+02,  2.4800e+02,        -inf,\n",
       "            1.4496e-01, -2.3442e+00, -4.3273e-01, -1.1498e-01,  1.7964e+00,\n",
       "           -4.7741e-01],\n",
       "          [ 2.7000e+02,  2.7100e+02,  2.7200e+02,  2.7300e+02,        -inf,\n",
       "           -1.5521e+00, -6.4898e-01, -7.7376e-02, -6.0421e-01, -5.2757e-01,\n",
       "            8.4868e-02],\n",
       "          [ 2.9500e+02,  2.9600e+02,  2.9700e+02,  2.9800e+02,        -inf,\n",
       "            1.9454e-01, -9.4179e-01, -1.8792e-01,  1.0325e+00, -2.4865e-01,\n",
       "           -4.7209e-01]]]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee = torch.cat([cc,dd],3)\n",
    "ee.shape\n",
    "ee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:05:18.128282Z",
     "start_time": "2020-09-16T05:05:18.124418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.Tensor([1,2,3]).repeat(3).reshape(3,3)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concate = self.softmax(torch.cat([energy_H, energy_W], 3)) computes the attention maps and one overlapped position was set to 0 by the self.INF, so there are H+W-1 non-zero values + 1 zero value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T07:43:52.690132Z",
     "start_time": "2020-09-16T07:43:52.642894Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/fastai2/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           9.4136e-02, 1.4478e-01, 7.6298e-02, 5.7486e-02, 1.4068e-01,\n",
       "           1.4787e-01],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           4.6530e-02, 4.9740e-02, 3.3694e-02, 2.5644e-01, 5.2072e-02,\n",
       "           9.9701e-02],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           3.9879e-02, 3.6223e-01, 2.5170e-01, 7.1195e-02, 8.9133e-02,\n",
       "           3.3599e-02],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           2.8305e-01, 9.4847e-02, 3.6853e-01, 2.5520e-01, 7.9204e-02,\n",
       "           1.3933e-01],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           2.5699e-01, 9.0260e-02, 1.3878e-02, 1.3686e-01, 1.5405e-01,\n",
       "           2.8697e-01],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           1.0946e-01, 1.2273e-01, 2.7974e-01, 1.0425e-01, 7.9957e-02,\n",
       "           6.1139e-02]],\n",
       "\n",
       "         [[3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           5.2816e-01, 3.2090e-01, 1.7099e-01, 1.7864e-01, 1.3916e-01,\n",
       "           3.6440e-01],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           1.0585e-01, 2.4156e-01, 7.2528e-01, 6.7077e-02, 5.4716e-01,\n",
       "           6.8292e-02],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           1.9702e-02, 1.1562e-01, 2.1403e-01, 2.8811e-02, 3.8364e-01,\n",
       "           1.6680e-01],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           4.5089e-01, 5.8323e-01, 1.7790e-01, 5.1096e-01, 1.2760e-01,\n",
       "           3.2619e-02],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           3.9806e-01, 4.5107e-02, 4.6866e-03, 2.7522e-01, 1.4126e-01,\n",
       "           1.9129e-01],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           1.3395e-01, 5.1217e-02, 3.4602e-02, 1.1120e-01, 3.6400e-01,\n",
       "           1.3388e-01]],\n",
       "\n",
       "         [[4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           2.1409e-01, 2.5472e-01, 5.4184e-02, 1.2518e-01, 9.8063e-02,\n",
       "           1.5531e-01],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           1.8410e-01, 9.3096e-02, 4.1387e-02, 2.0913e-01, 5.8908e-02,\n",
       "           2.6649e-01],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           1.1867e-02, 4.0624e-02, 2.3781e-01, 3.8008e-02, 2.3084e-01,\n",
       "           6.4929e-02],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           4.9645e-02, 1.6165e-01, 5.4352e-02, 1.2481e-01, 2.0563e-01,\n",
       "           4.5498e-01],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           1.6547e-01, 3.5374e-01, 2.9660e-01, 2.3320e-01, 5.7896e-01,\n",
       "           2.3587e-01],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           9.6168e-02, 4.2563e-01, 1.6235e-01, 2.0504e-01, 6.1576e-02,\n",
       "           1.1391e-01]],\n",
       "\n",
       "         [[6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           5.2892e-02, 1.6491e-01, 3.3461e-02, 9.2538e-02, 3.7257e-01,\n",
       "           1.5528e-01],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           4.4839e-01, 5.6269e-01, 8.4332e-02, 2.5680e-01, 1.9357e-01,\n",
       "           8.3300e-02],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           6.4308e-01, 5.3081e-02, 1.9762e-01, 2.8670e-01, 2.4697e-02,\n",
       "           6.4797e-01],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           1.5570e-01, 1.0920e-01, 3.1614e-01, 3.3823e-02, 2.1894e-01,\n",
       "           2.0626e-01],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           6.3078e-02, 1.8482e-02, 2.4733e-01, 2.6010e-01, 2.8933e-02,\n",
       "           8.1901e-02],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           4.1853e-01, 2.7105e-01, 4.2400e-01, 2.2004e-01, 3.7881e-01,\n",
       "           2.2028e-02]],\n",
       "\n",
       "         [[9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           1.1073e-01, 1.1469e-01, 6.6507e-01, 5.4616e-01, 2.4953e-01,\n",
       "           1.7714e-01],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           2.1513e-01, 5.2907e-02, 1.1530e-01, 2.1055e-01, 1.4829e-01,\n",
       "           4.8222e-01],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           2.8547e-01, 4.2844e-01, 9.8836e-02, 5.7529e-01, 2.7168e-01,\n",
       "           8.6707e-02],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           6.0712e-02, 5.1069e-02, 8.3078e-02, 7.5215e-02, 3.6862e-01,\n",
       "           1.6681e-01],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           1.1639e-01, 4.9241e-01, 4.3751e-01, 9.4617e-02, 9.6799e-02,\n",
       "           2.0397e-01],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           2.4188e-01, 1.2938e-01, 9.9304e-02, 3.5947e-01, 1.1566e-01,\n",
       "           6.6905e-01]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           5.8554e-02, 1.6851e-01, 1.2269e-01, 1.5182e-01, 5.8878e-01,\n",
       "           1.2124e-01],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           1.6878e-01, 2.9719e-01, 5.3604e-02, 3.1655e-01, 1.1193e-01,\n",
       "           3.2769e-01],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           7.9988e-02, 1.5148e-01, 6.8000e-01, 1.1551e-01, 2.0757e-01,\n",
       "           1.3382e-02],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           9.7955e-03, 4.9814e-02, 7.5488e-02, 4.0652e-01, 4.0360e-02,\n",
       "           3.4369e-01],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           5.7499e-02, 1.1826e-01, 2.0408e-01, 1.6964e-01, 2.7016e-01,\n",
       "           5.6922e-01],\n",
       "          [0.0000e+00, 2.0473e-09, 2.0474e-09, 2.0611e-09, 3.0384e-07,\n",
       "           1.6158e-01, 6.2562e-01, 1.8498e-01, 4.9499e-01, 6.2669e-01,\n",
       "           4.4747e-01]],\n",
       "\n",
       "         [[3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           5.8260e-02, 5.1139e-01, 4.8475e-01, 1.2812e-01, 1.3089e-01,\n",
       "           9.2482e-02],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           5.7068e-01, 4.5547e-01, 2.5172e-01, 6.8382e-02, 1.2013e-01,\n",
       "           3.0132e-02],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           4.9149e-01, 2.3433e-01, 1.6891e-01, 2.0685e-01, 1.1451e-01,\n",
       "           1.1947e-01],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           4.6754e-01, 2.2014e-02, 7.2730e-01, 1.5606e-02, 3.8507e-02,\n",
       "           2.7085e-01],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           3.3452e-01, 3.5947e-01, 4.2665e-01, 9.1849e-02, 5.1865e-02,\n",
       "           1.6334e-01],\n",
       "          [3.0384e-07, 0.0000e+00, 3.0385e-07, 3.0589e-07, 4.5094e-05,\n",
       "           2.1614e-01, 1.6163e-01, 2.1280e-01, 4.0822e-02, 5.6359e-02,\n",
       "           3.2662e-01]],\n",
       "\n",
       "         [[4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           1.3814e-01, 4.4961e-02, 1.3197e-01, 3.8146e-01, 2.9957e-02,\n",
       "           4.0217e-01],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           1.5715e-01, 1.6432e-01, 5.4057e-01, 2.9228e-01, 1.0140e-01,\n",
       "           2.2434e-02],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           4.1024e-02, 3.1781e-01, 3.7427e-02, 3.0264e-01, 6.8877e-02,\n",
       "           7.0646e-01],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           1.0526e-01, 7.5111e-03, 4.2710e-02, 5.4257e-02, 2.0816e-01,\n",
       "           1.2301e-01],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           2.2153e-01, 1.3602e-01, 2.0226e-01, 4.6453e-01, 2.5152e-01,\n",
       "           2.9422e-02],\n",
       "          [4.5094e-05, 4.5094e-05, 0.0000e+00, 4.5398e-05, 6.6925e-03,\n",
       "           1.9317e-01, 8.3385e-02, 2.0037e-01, 2.2873e-01, 1.3558e-01,\n",
       "           6.6700e-02]],\n",
       "\n",
       "         [[6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           1.2098e-01, 3.7763e-02, 1.8905e-01, 2.4358e-01, 2.2186e-02,\n",
       "           5.6013e-02],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           5.5396e-02, 4.8306e-02, 1.3027e-01, 9.9335e-02, 5.1201e-01,\n",
       "           2.3673e-01],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           3.1052e-01, 2.5761e-01, 4.8801e-02, 2.3448e-01, 3.5360e-01,\n",
       "           6.1793e-02],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           2.0813e-01, 9.1223e-01, 7.0361e-02, 3.7558e-01, 1.2497e-01,\n",
       "           1.3717e-01],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           3.2932e-01, 3.1276e-01, 7.5820e-02, 1.8641e-01, 3.6201e-01,\n",
       "           2.0383e-02],\n",
       "          [6.6925e-03, 6.6925e-03, 6.6928e-03, 0.0000e+00, 9.9326e-01,\n",
       "           9.8756e-02, 6.6425e-02, 2.8070e-01, 3.0498e-02, 1.0347e-01,\n",
       "           8.4991e-02]],\n",
       "\n",
       "         [[9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           6.2406e-01, 2.3737e-01, 7.1541e-02, 9.5024e-02, 2.2819e-01,\n",
       "           3.2810e-01],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           4.8001e-02, 3.4709e-02, 2.3838e-02, 2.2346e-01, 1.5453e-01,\n",
       "           3.8301e-01],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           7.6984e-02, 3.8770e-02, 6.4861e-02, 1.4053e-01, 2.5544e-01,\n",
       "           9.8890e-02],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           2.0927e-01, 8.4268e-03, 8.4143e-02, 1.4804e-01, 5.8800e-01,\n",
       "           1.2528e-01],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           5.7135e-02, 7.3493e-02, 9.1185e-02, 8.7567e-02, 6.4452e-02,\n",
       "           2.1764e-01],\n",
       "          [9.9326e-01, 9.9326e-01, 9.9331e-01, 9.9995e-01, 0.0000e+00,\n",
       "           3.3035e-01, 6.2940e-02, 1.2116e-01, 2.0496e-01, 7.7897e-02,\n",
       "           7.4217e-02]]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:48:49.249956Z",
     "start_time": "2020-09-16T09:48:49.241838Z"
    }
   },
   "outputs": [],
   "source": [
    "con1 = [1,2,3]\n",
    "con2 = [4,5,6]\n",
    "out = [con1,con2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T06:26:52.757572Z",
     "start_time": "2020-09-17T06:26:52.495277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CC_module(\n",
       "  (query_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (key_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (value_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (softmax): Softmax(dim=3)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# explore the relationship between classes and context information\n",
    "#  Class Oriented Context Fusion Module\n",
    "class CC_module(nn.Module):\n",
    "    def __init__(self,in_dim):\n",
    "        super(CC_module, self).__init__()\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.softmax = Softmax(dim=3)\n",
    "        self.INF = INF\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self, x):\n",
    "        m_batchsize, _, height, width = x.size() # [2, 64, 5, 6] BCHW\n",
    "        proj_query = self.query_conv(x) # [2, 8, 5, 6]\n",
    "        proj_query_H = proj_query.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height).permute(0, 2, 1) # [12, 5, 8]\n",
    "        proj_query_W = proj_query.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width).permute(0, 2, 1) # [10, 6, 8]\n",
    "        proj_key = self.key_conv(x)# [2, 8, 5, 6]\n",
    "        proj_key_H = proj_key.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height)   # [12, 8, 5]\n",
    "        proj_key_W = proj_key.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width) # [10, 8, 6]\n",
    "        proj_value = self.value_conv(x) # [2, 64, 5, 6]\n",
    "        proj_value_H = proj_value.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height)   # [12, 64, 5]\n",
    "        proj_value_W = proj_value.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width)   # [10, 64, 6]\n",
    "        energy_H = (torch.bmm(proj_query_H, proj_key_H)+self.INF(m_batchsize, height, width)).view(m_batchsize,width,height,height).permute(0,2,1,3)# [12,5,5] -- > [2, 5, 6, 5]\n",
    "        energy_W = torch.bmm(proj_query_W, proj_key_W).view(m_batchsize,height,width,width) #[2, 5, 6, 6]\n",
    "        concate = self.softmax(torch.cat([energy_H, energy_W], 3))# [2,5,6,11]\n",
    "\n",
    "        att_H = concate[:,:,:,0:height].permute(0,2,1,3).contiguous().view(m_batchsize*width,height,height) #[12,5,5]\n",
    "        #print(concate)\n",
    "        #print(att_H) \n",
    "        att_W = concate[:,:,:,height:height+width].contiguous().view(m_batchsize*height,width,width)# [10, 6, 6]\n",
    "        out_H = torch.bmm(proj_value_H, att_H.permute(0, 2, 1)).view(m_batchsize,width,-1,height).permute(0,2,3,1) # [2, 64, 5, 6]\n",
    "        out_W = torch.bmm(proj_value_W, att_W.permute(0, 2, 1)).view(m_batchsize,height,-1,width).permute(0,2,1,3)#[2, 64, 5, 6])\n",
    "        #print(out_H.size(),out_W.size())\n",
    "        return self.gamma*(out_H + out_W) + x\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = CC_module(64)\n",
    "    # cuda0 = torch.device('cuda:0')\n",
    "    model.cuda()\n",
    "    x = torch.randn(2, 64, 5, 6).cuda()\n",
    "    out = model(x)\n",
    "    print(out.shape)\n",
    "    torch.cuda.empty_cache()\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class _ObjectAttentionBlock(nn.Module):\n",
    "    '''\n",
    "    The basic implementation for object context block\n",
    "    Input:\n",
    "        N X C X H X W\n",
    "    Parameters:\n",
    "        in_channels       : the dimension of the input feature map\n",
    "        key_channels      : the dimension after the key/query transform\n",
    "        scale             : choose the scale to downsample the input feature maps (save memory cost)\n",
    "        bn_type           : specify the bn type\n",
    "    Return:\n",
    "        N X C X H X W\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 scale=1, \n",
    "                 bn_type=None):\n",
    "        super(_ObjectAttentionBlock, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.in_channels = in_channels\n",
    "        self.key_channels = key_channels\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(scale, scale))\n",
    "        self.f_pixel = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_object = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_up = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.in_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.in_channels, bn_type=bn_type),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, proxy):\n",
    "        # x ([1, 512, 64, 64]) proxy [1, 512, 19, 1]\n",
    "        batch_size, h, w = x.size(0), x.size(2), x.size(3)\n",
    "        if self.scale > 1:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        query = self.f_pixel(x).view(batch_size, self.key_channels, -1)# key 256\n",
    "        query = query.permute(0, 2, 1) # (1,4096,256)\n",
    "        key = self.f_object(proxy).view(batch_size, self.key_channels, -1)# [1, 256, 19])\n",
    "        value = self.f_down(proxy).view(batch_size, self.key_channels, -1)# \n",
    "        value = value.permute(0, 2, 1)# [1, 19, 256]\n",
    "\n",
    "        sim_map = torch.matmul(query, key)# [1, 4096, 19]\n",
    "        sim_map = (self.key_channels**-.5) * sim_map # [1, 4096, 19]\n",
    "        sim_map = F.softmax(sim_map, dim=-1)   # [1, 4096, 19]\n",
    "\n",
    "        # add bg context ...\n",
    "        context = torch.matmul(sim_map, value) # [1, 4096, 256]\n",
    "        context = context.permute(0, 2, 1).contiguous() # [1, 256, 4096]\n",
    "        context = context.view(batch_size, self.key_channels, *x.size()[2:])#[1, 256, 64, 64] \n",
    "        context = self.f_up(context)#[1, 512, 64, 64]\n",
    "        if self.scale > 1:\n",
    "            context = F.interpolate(input=context, size=(h, w), mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _CrossAttention(nn.Module):\n",
    "    def __init__(self,in_dim):\n",
    "        super(CC_module, self).__init__()\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.softmax = Softmax(dim=3)\n",
    "        self.INF = INF\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self, x):\n",
    "        m_batchsize, _, height, width = x.size() # [2, 64, 5, 6] BCHW\n",
    "        \n",
    "        proj_query = self.query_conv(x) # [2, 8, 5, 6]\n",
    "        proj_query_H = proj_query.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height).permute(0, 2, 1) # [12, 5, 8]\n",
    "        proj_query_W = proj_query.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width).permute(0, 2, 1) # [10, 6, 8]\n",
    "        \n",
    "        proj_key = self.key_conv(x)# [2, 8, 5, 6]\n",
    "        proj_key_H = proj_key.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height)   # [12, 8, 5]\n",
    "        proj_key_W = proj_key.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width) # [10, 8, 6]\n",
    "        \n",
    "        proj_value = self.value_conv(x) # [2, 64, 5, 6]\n",
    "        proj_value_H = proj_value.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height)   # [12, 64, 5]\n",
    "        proj_value_W = proj_value.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width)   # [10, 64, 6]\n",
    "        \n",
    "        energy_H = (torch.bmm(proj_query_H, proj_key_H)+self.INF(m_batchsize, height, width)).view(m_batchsize,width,height,height).permute(0,2,1,3)# [12,5,5] -- > [2, 5, 6, 5]\n",
    "        energy_W = torch.bmm(proj_query_W, proj_key_W).view(m_batchsize,height,width,width) #[2, 5, 6, 6]\n",
    "        concate = self.softmax(torch.cat([energy_H, energy_W], 3))# [2,5,6,11]\n",
    "\n",
    "        att_H = concate[:,:,:,0:height].permute(0,2,1,3).contiguous().view(m_batchsize*width,height,height) #[12,5,5]\n",
    "        #print(concate)\n",
    "        #print(att_H) \n",
    "        att_W = concate[:,:,:,height:height+width].contiguous().view(m_batchsize*height,width,width)# [10, 6, 6]\n",
    "        \n",
    "        out_H = torch.bmm(proj_value_H, att_H.permute(0, 2, 1)).view(m_batchsize,width,-1,height).permute(0,2,3,1) # [2, 64, 5, 6]\n",
    "        out_W = torch.bmm(proj_value_W, att_W.permute(0, 2, 1)).view(m_batchsize,height,-1,width).permute(0,2,1,3)#[2, 64, 5, 6])\n",
    "        \n",
    "        #print(out_H.size(),out_W.size())\n",
    "        return self.gamma*(out_H + out_W) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T04:33:13.454659Z",
     "start_time": "2020-09-18T04:33:13.436593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [5., 6., 7.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = nn.Parameter(torch.zeros(1))\n",
    "test\n",
    "aa = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "bb = torch.ones(2,3)\n",
    "aa + bb\n",
    "(test*aa)\n",
    "64**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:26:29.552494Z",
     "start_time": "2020-09-24T02:26:29.544758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = torch.zeros(1)\n",
    "aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python37564bitfastai2conda0460244ff620488f9ecf7aa8887aa15c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
