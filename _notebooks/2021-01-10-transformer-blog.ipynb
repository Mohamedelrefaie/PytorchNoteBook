{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Blog\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- sticky_rank: 2\n",
    "- author: Bowen\n",
    "- categories: [pytorch, fastai]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference links which helps a lot:\n",
    "  - [1] http://jalammar.github.io/illustrated-transformer/\n",
    "  - [2] http://peterbloem.nl/blog/transformers\n",
    "  - [3] https://nlp.seas.harvard.edu/2018/04/03/attention.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:50:16.516707Z",
     "start_time": "2021-01-12T01:50:16.194271Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self-attention method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.loli.net/2021/01/11/D2rtu9nGSVbdAUq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.loli.net/2021/01/11/VW1UubNORzTy7E6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:12:35.647133Z",
     "start_time": "2021-01-11T10:12:35.634015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.7608e-01, 1.4019e-01, 4.8374e-01],\n",
       "         [1.3241e-02, 9.8102e-01, 5.7356e-03],\n",
       "         [6.7872e-02, 8.5199e-03, 9.2361e-01]],\n",
       "\n",
       "        [[8.6212e-01, 1.9809e-02, 1.1807e-01],\n",
       "         [6.0491e-04, 9.8575e-01, 1.3647e-02],\n",
       "         [1.1610e-01, 4.3942e-01, 4.4448e-01]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3,4)\n",
    "raw_weights = torch.bmm(x,x.transpose(1,2))\n",
    "weights = F.softmax(raw_weights,dim=2)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:13:20.327542Z",
     "start_time": "2021-01-11T10:13:20.317312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7534,  0.1771, -0.0526, -0.4511],\n",
       "         [ 0.0585, -1.1643,  1.3854,  0.4464],\n",
       "         [ 1.2452,  0.3228, -0.4401, -0.9620]],\n",
       "\n",
       "        [[-0.8668,  0.0406,  0.0529, -0.2900],\n",
       "         [ 1.9601, -0.1198, -0.9540,  0.3403],\n",
       "         [ 0.9987, -0.2199, -0.2520, -0.0090]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.bmm(weights,x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T10:18:57.017777Z",
     "start_time": "2021-01-11T10:18:56.999921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4912394464713312614"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.5000],\n",
       "        [0.2689, 0.5000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.seed()\n",
    "temp = torch.randint(0,2,(2,2))\n",
    "temp\n",
    "yy = F.softmax(temp.float(),dim=0)\n",
    "yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.loli.net/2021/01/11/IshpEO5UHlXvw8k.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:54:25.506762Z",
     "start_time": "2021-01-10T01:54:25.499472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 9, 7, 7],\n",
       "       [2, 3, 3, 4],\n",
       "       [2, 2, 8, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.random.randint(1,10,(3,4))\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:55:32.588825Z",
     "start_time": "2021-01-10T01:55:32.582163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 7],\n",
       "       [2, 3],\n",
       "       [2, 8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[:,0::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T14:24:38.701894Z",
     "start_time": "2021-01-11T14:24:38.258478Z"
    }
   },
   "outputs": [],
   "source": [
    "class SelfAttentionWide(nn.Module):\n",
    "    def __init__(self, emb, heads=8, mask=False):\n",
    "        \"\"\"\n",
    "        :param emb:\n",
    "        :param heads:\n",
    "        :param mask:\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = emb\n",
    "        self.heads = heads\n",
    "        self.mask = mask\n",
    "\n",
    "        self.tokeys = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.toqueries = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.tovalues = nn.Linear(emb, emb * heads, bias=False)\n",
    "\n",
    "        self.unifyheads = nn.Linear(heads * emb, emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        b, t, e = x.size()\n",
    "        h = self.heads\n",
    "        assert e == self.emb, f'Input embedding dim ({e}) should match layer embedding dim ({self.emb})'\n",
    "\n",
    "        keys    = self.tokeys(x)   .view(b, t, h, e)\n",
    "        queries = self.toqueries(x).view(b, t, h, e)\n",
    "        values  = self.tovalues(x) .view(b, t, h, e)\n",
    "\n",
    "        # compute scaled dot-product self-attention\n",
    "\n",
    "        # - fold heads into the batch dimension\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * h, t, e)\n",
    "\n",
    "        queries = queries / (e ** (1/4))\n",
    "        keys    = keys / (e ** (1/4))\n",
    "        # - Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n",
    "        #   This should be more memory efficient\n",
    "\n",
    "        # - get dot product of queries and keys, and scale\n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "\n",
    "        assert dot.size() == (b*h, t, t)\n",
    "\n",
    "        if self.mask: # mask out the upper half of the dot matrix, excluding the diagonal\n",
    "            mask_(dot, maskval=float('-inf'), mask_diagonal=False)\n",
    "\n",
    "        dot = F.softmax(dot, dim=2)\n",
    "        # - dot now has row-wise self-attention probabilities\n",
    "\n",
    "        # apply the self attention to the values\n",
    "        out = torch.bmm(dot, values).view(b, h, t, e)\n",
    "\n",
    "        # swap h, t back, unify heads\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, h * e)\n",
    "\n",
    "        return self.unifyheads(out)\n",
    "\n",
    "class SelfAttentionNarrow(nn.Module):\n",
    "\n",
    "    def __init__(self, emb, heads=8, mask=False):\n",
    "        \"\"\"\n",
    "        :param emb:\n",
    "        :param heads:\n",
    "        :param mask:\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        assert emb % heads == 0, f'Embedding dimension ({emb}) should be divisible by nr. of heads ({heads})'\n",
    "\n",
    "        self.emb = emb\n",
    "        self.heads = heads\n",
    "        self.mask = mask\n",
    "\n",
    "        s = emb // heads\n",
    "        # - We will break the embedding into `heads` chunks and feed each to a different attention head\n",
    "\n",
    "        self.tokeys    = nn.Linear(s, s, bias=False)\n",
    "        self.toqueries = nn.Linear(s, s, bias=False)\n",
    "        self.tovalues  = nn.Linear(s, s, bias=False)\n",
    "\n",
    "        self.unifyheads = nn.Linear(heads * s, emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        b, t, e = x.size()\n",
    "        h = self.heads\n",
    "        assert e == self.emb, f'Input embedding dim ({e}) should match layer embedding dim ({self.emb})'\n",
    "\n",
    "        s = e // h\n",
    "        x = x.view(b, t, h, s)\n",
    "\n",
    "        keys    = self.tokeys(x)\n",
    "        queries = self.toqueries(x)\n",
    "        values  = self.tovalues(x)\n",
    "\n",
    "        assert keys.size() == (b, t, h, s)\n",
    "        assert queries.size() == (b, t, h, s)\n",
    "        assert values.size() == (b, t, h, s)\n",
    "\n",
    "        # Compute scaled dot-product self-attention\n",
    "\n",
    "        # - fold heads into the batch dimension\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "\n",
    "        queries = queries / (e ** (1/4))\n",
    "        keys    = keys / (e ** (1/4))\n",
    "        # - Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n",
    "        #   This should be more memory efficient\n",
    "\n",
    "        # - get dot product of queries and keys, and scale\n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "\n",
    "        assert dot.size() == (b*h, t, t)\n",
    "\n",
    "        if self.mask: # mask out the upper half of the dot matrix, excluding the diagonal\n",
    "            mask_(dot, maskval=float('-inf'), mask_diagonal=False)\n",
    "\n",
    "        dot = F.softmax(dot, dim=2)\n",
    "        # - dot now has row-wise self-attention probabilities\n",
    "\n",
    "        # apply the self attention to the values\n",
    "        out = torch.bmm(dot, values).view(b, h, t, s)\n",
    "\n",
    "        # swap h, t back, unify heads\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, s * h)\n",
    "\n",
    "        return self.unifyheads(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also change the code using einsum which help to short the code part and have a nice execution time https://rockt.github.io/2018/04/30/einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T14:58:07.680299Z",
     "start_time": "2021-01-11T14:58:07.617916Z"
    }
   },
   "outputs": [],
   "source": [
    "class SelfAttentionWideEinsum(nn.Module):\n",
    "    def __init__(self, emb, heads=8, mask=False):\n",
    "        \"\"\"\n",
    "        :param emb:\n",
    "        :param heads:\n",
    "        :param mask:\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = emb\n",
    "        self.heads = heads\n",
    "        self.mask = mask\n",
    "\n",
    "        self.tokeys = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.toqueries = nn.Linear(emb, emb * heads, bias=False)\n",
    "        self.tovalues = nn.Linear(emb, emb * heads, bias=False)\n",
    "\n",
    "        self.unifyheads = nn.Linear(heads * emb, emb)\n",
    "    def forward_einsum(self, x):\n",
    "        b, t, e = x.size()\n",
    "        h = self.heads\n",
    "\n",
    "        keys    = self.tokeys(x).view(b, t, h, e)\n",
    "        queries = self.toqueries(x).view(b, t, h, e)\n",
    "        values  = self.tovalues(x).view(b, t, h, e)\n",
    "\n",
    "        dot = torch.einsum('bthe,bihe->bhti', queries, keys) / math.sqrt(e)\n",
    "        dot = F.softmax(dot, dim=-1)\n",
    "\n",
    "        out = torch.einsum('bhtd,bdhe->bthe', dot, values)\n",
    "\n",
    "        # we can move reshape of weights to init; I left it here just to compare with the original implementation\n",
    "        out = torch.einsum('bthe,khe->btk', out, self.unifyheads.weight.view(e,h,e)) \n",
    "        return out + self.unifyheads.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.loli.net/2021/01/11/ri7wu9jPdohARF1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T15:03:12.961063Z",
     "start_time": "2021-01-11T15:03:12.911300Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, emb, heads, mask, seq_length, ff_hidden_mult=4, dropout=0.0, wide=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = SelfAttentionWide(emb, heads=heads, mask=mask) if wide \\\n",
    "                    else SelfAttentionNarrow(emb, heads=heads, mask=mask)\n",
    "        self.mask = mask\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(emb)\n",
    "        self.norm2 = nn.LayerNorm(emb)\n",
    "'''\n",
    "We’ve made the relatively arbitrary choice of making the hidden layer\n",
    "of the feedforward 4 times as big as the input and output. Smaller values may work as well, \n",
    "and save memory, but it should be bigger than the input/output layers.\n",
    "'''\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(emb, ff_hidden_mult * emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_mult * emb, emb)\n",
    "        )\n",
    "\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        attended = self.attention(x)\n",
    "\n",
    "        x = self.norm1(attended + x)\n",
    "\n",
    "        x = self.do(x)\n",
    "\n",
    "        fedforward = self.ff(x)\n",
    "\n",
    "        x = self.norm2(fedforward + x)\n",
    "\n",
    "        x = self.do(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## position embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T15:19:49.961126Z",
     "start_time": "2021-01-11T15:19:49.955322Z"
    }
   },
   "outputs": [],
   "source": [
    "def d(tensor=None):\n",
    "    \"\"\"\n",
    "    Returns a device string either for the best available device,\n",
    "    or for the device corresponding to the argument\n",
    "    :param tensor:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if tensor is None:\n",
    "        return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    return 'cuda' if tensor.is_cuda else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T15:37:18.140539Z",
     "start_time": "2021-01-11T15:37:18.132607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9651,  1.4951, -0.0168,  0.7085],\n",
       "         [-1.9934, -0.5921, -0.3682, -0.8308],\n",
       "         [ 1.0251, -0.0033, -1.4288,  0.4307]],\n",
       "\n",
       "        [[-0.1145,  0.4717, -0.5771,  0.8367],\n",
       "         [ 0.8415, -0.2907,  2.7137, -0.3131],\n",
       "         [ 1.2084,  0.0839, -0.4571, -0.1604]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.randn(2,3,4)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T15:48:15.277718Z",
     "start_time": "2021-01-11T15:48:15.266950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0416, -1.2013, -1.1024, -0.2295,  0.7987,  0.5698],\n",
       "         [-0.9966,  0.5302, -0.6908, -2.4040, -0.1549, -0.0050],\n",
       "         [ 0.1405, -0.4664, -0.2933, -0.0160,  0.0548, -0.3741]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> # an Embedding module containing 10 tensors of size 6\n",
    ">>> embedding = nn.Embedding(10, 6)\n",
    ">>> # a batch of 2 samples of 4 indices each\n",
    ">>> input = torch.LongTensor([[1,2,3]])\n",
    ">>> embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T15:37:34.942798Z",
     "start_time": "2021-01-11T15:37:34.937991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[None,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T15:49:02.644248Z",
     "start_time": "2021-01-11T15:49:02.632017Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6559, -0.3209,  2.2730,  0.3641, -1.5789, -1.0718],\n",
       "         [-0.3217,  0.2345,  1.8767, -0.8459, -1.0136,  0.1944],\n",
       "         [ 0.2643, -1.5120, -0.1799,  1.8587,  0.7489,  0.0663],\n",
       "         [-0.2499,  0.6199,  0.6119, -0.1948, -1.2249, -0.9786],\n",
       "         [-0.0888,  1.4573, -0.0139, -1.5792,  1.0114, -0.6898]],\n",
       "\n",
       "        [[-1.6559, -0.3209,  2.2730,  0.3641, -1.5789, -1.0718],\n",
       "         [-0.3217,  0.2345,  1.8767, -0.8459, -1.0136,  0.1944],\n",
       "         [ 0.2643, -1.5120, -0.1799,  1.8587,  0.7489,  0.0663],\n",
       "         [-0.2499,  0.6199,  0.6119, -0.1948, -1.2249, -0.9786],\n",
       "         [-0.0888,  1.4573, -0.0139, -1.5792,  1.0114, -0.6898]],\n",
       "\n",
       "        [[-1.6559, -0.3209,  2.2730,  0.3641, -1.5789, -1.0718],\n",
       "         [-0.3217,  0.2345,  1.8767, -0.8459, -1.0136,  0.1944],\n",
       "         [ 0.2643, -1.5120, -0.1799,  1.8587,  0.7489,  0.0663],\n",
       "         [-0.2499,  0.6199,  0.6119, -0.1948, -1.2249, -0.9786],\n",
       "         [-0.0888,  1.4573, -0.0139, -1.5792,  1.0114, -0.6898]]],\n",
       "       grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b,t,e = 3,5,6\n",
    "position = nn.Embedding(10,6)(torch.arange(t))[None, :, :].expand(b, t, e)\n",
    "position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## position encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:50:54.659849Z",
     "start_time": "2021-01-10T01:50:54.634579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code from https://www.tensorflow.org/tutorials/text/transformer\n",
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:56:05.045536Z",
     "start_time": "2021-01-10T01:56:04.777140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f943d17ac50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Embedding Dimensions')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 64.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10.0, 0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Token Position')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f943d12c5c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = 10\n",
    "dimensions = 64\n",
    "\n",
    "pos_encoding = positional_encoding(tokens, dimensions)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.pcolormesh(pos_encoding[0], cmap='viridis')\n",
    "plt.xlabel('Embedding Dimensions')\n",
    "plt.xlim((0, dimensions))\n",
    "plt.ylim((tokens,0))\n",
    "plt.ylabel('Token Position')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:50:22.888557Z",
     "start_time": "2021-01-12T01:50:22.841065Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, k, heads, depth, seq_length, num_tokens, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_emb = nn.Embedding(num_tokens, k)\n",
    "        self.pos_emb = nn.Embedding(seq_length, k)\n",
    "\n",
    "\t\t# The sequence of transformer blocks that does all the \n",
    "\t\t# heavy lifting\n",
    "        tblocks = []\n",
    "        for i in range(depth):\n",
    "            tblocks.append(TransformerBlock(k=k, heads=heads))\n",
    "        self.tblocks = nn.Sequential(*tblocks)\n",
    "\n",
    "\t\t# Maps the final output sequence to class logits\n",
    "        self.toprobs = nn.Linear(k, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: A (b, t) tensor of integer values representing \n",
    "                  words (in some predetermined vocabulary).\n",
    "        :return: A (b, c) tensor of log-probabilities over the \n",
    "                 classes (where c is the nr. of classes).\n",
    "        \"\"\"\n",
    "\t\t# generate token embeddings\n",
    "        tokens = self.token_emb(x)\n",
    "        b, t, k = tokens.size()\n",
    "\n",
    "\t\t# generate position embeddings\n",
    "        positions = torch.arange(t)\n",
    "        positions = self.pos_emb(positions)[None, :, :].expand(b, t, k)\n",
    "        \n",
    "        x = tokens + positions\n",
    "        x = self.tblocks(x)\n",
    "        \n",
    "        # Average-pool over the t dimension and project to class \n",
    "        # probabilities\n",
    "        x = self.toprobs(x.mean(dim=1))\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.loli.net/2021/01/12/PshiNdajJzu6oOR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://pytorch.org/docs/stable/generated/torch.triu.html#torch.triu\n",
    "https://pytorch.org/docs/stable/generated/torch.triu_indices.html#torch.triu_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T02:17:47.807240Z",
     "start_time": "2021-01-12T02:17:47.799312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 1, 1, 2, 2, 3]), array([0, 1, 2, 3, 1, 2, 3, 2, 3, 3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iu1 = np.triu_indices(4)\n",
    "iu2 = np.triu_indices(4,2)\n",
    "iu1\n",
    "# iu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T02:20:39.788672Z",
     "start_time": "2021-01-12T02:20:39.780700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  5,  6,  7, 10, 11, 15])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(16).reshape(4,4)\n",
    "a[iu1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T02:20:59.304034Z",
     "start_time": "2021-01-12T02:20:59.297026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T02:21:05.068662Z",
     "start_time": "2021-01-12T02:21:05.061985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[iu2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T03:17:26.919181Z",
     "start_time": "2021-01-12T03:17:26.904977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 1, 1, 2, 2, 3],\n",
       "        [0, 1, 2, 3, 1, 2, 3, 2, 3, 3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iu1 = torch.triu_indices(4,4)\n",
    "a = torch.arange(16).view(4,4)\n",
    "a \n",
    "iu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T03:18:42.006789Z",
     "start_time": "2021-01-12T03:18:42.001949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  5,  6,  7, 10, 11, 15])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[iu1[0],iu1[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T03:19:38.706755Z",
     "start_time": "2021-01-12T03:19:38.696593Z"
    }
   },
   "outputs": [],
   "source": [
    "# mask function\n",
    "def mask_(matrices, maskval=0.0, mask_diagonal=True):\n",
    "    \"\"\"\n",
    "    Masks out all values in the given batch of matrices where i <= j holds,\n",
    "    i < j if mask_diagonal is false\n",
    "    In place operation\n",
    "    :param tns:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    b, h, w = matrices.size()\n",
    "\n",
    "    indices = torch.triu_indices(h, w, offset=0 if mask_diagonal else 1)\n",
    "    matrices[:, indices[0], indices[1]] = maskval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T03:23:25.625830Z",
     "start_time": "2021-01-12T03:23:25.604443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1],\n",
       "        [1, 2, 2]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [9.0848e-01, 9.1524e-02, 0.0000e+00],\n",
       "         [2.5938e-04, 9.9937e-01, 3.6845e-04]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = torch.randn(1,3,3)\n",
    "keys = torch.randn(1,3,3)\n",
    "t = 3\n",
    "dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "\n",
    "indices = torch.triu_indices(t, t, offset=1)\n",
    "dot[:, indices[0], indices[1]] = float('-inf')\n",
    "\n",
    "dot = F.softmax(dot, dim=2) \n",
    "indices\n",
    "dot\n",
    "dot[:, indices[0], indices[1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('pytorch1.6': conda)",
   "language": "python",
   "name": "python361264bitpytorch16conda53ea58bece7547969f51ef43debfc3c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
